{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv(\"Desktop/emoint tweet/fear-ratings-0to1.train.txt\", delimiter='\\t', header=None)\n",
    "df1.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id                                              tweet emotion  score\n",
      "0     20000  I feel like I am drowning. #depression #anxiet...    fear  0.979\n",
      "1     20001  I get so nervous even thinking about talking t...    fear  0.979\n",
      "2     20002                     I lost my blinders .... #panic    fear  0.975\n",
      "3     20003  I feel like I am drowning. #depression  #falur...    fear  0.938\n",
      "4     20004  This is the scariest American Horror Story out...    fear  0.938\n",
      "...     ...                                                ...     ...    ...\n",
      "1142  21142     Pull over #tonight and make your car #shake ðŸ˜‹ðŸ’¦    fear  0.104\n",
      "1143  21143  @Melanie_Pierce @HunterHayes awe ain't he a sw...    fear  0.083\n",
      "1144  21144         @FraserKeegan just had a steak pie supper     fear  0.083\n",
      "1145  21145      @annalisewrobel_ awe thank you so much love ðŸ’•    fear  0.062\n",
      "1146  21146                             Omg he kissed herðŸ™ˆ  #w    fear  0.062\n",
      "\n",
      "[1147 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "df1['tweet'] = df1['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(remove_mentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s#@]', '', text)  \n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>i feel like i am drowning #depression #anxiety...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>i get so nervous even thinking about talking t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>i lost my blinders #panic</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>i feel like i am drowning #depression #falure ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>this is the scariest american horror story out...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>21142</td>\n",
       "      <td>pull over #tonight and make your car #shake</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>21143</td>\n",
       "      <td>awe aint he a sweetheart hes adorable</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>21144</td>\n",
       "      <td>just had a steak pie supper</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>21145</td>\n",
       "      <td>awe thank you so much love</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>21146</td>\n",
       "      <td>omg he kissed her #w</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1147 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              tweet emotion  score\n",
       "0     20000  i feel like i am drowning #depression #anxiety...    fear  0.979\n",
       "1     20001  i get so nervous even thinking about talking t...    fear  0.979\n",
       "2     20002                          i lost my blinders #panic    fear  0.975\n",
       "3     20003  i feel like i am drowning #depression #falure ...    fear  0.938\n",
       "4     20004  this is the scariest american horror story out...    fear  0.938\n",
       "...     ...                                                ...     ...    ...\n",
       "1142  21142        pull over #tonight and make your car #shake    fear  0.104\n",
       "1143  21143              awe aint he a sweetheart hes adorable    fear  0.083\n",
       "1144  21144                        just had a steak pie supper    fear  0.083\n",
       "1145  21145                         awe thank you so much love    fear  0.062\n",
       "1146  21146                               omg he kissed her #w    fear  0.062\n",
       "\n",
       "[1147 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji(tweet):\n",
    "    text = emoji.demojize(tweet)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tweet'] = df1['tweet'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>[i, feel, like, i, am, drowning, #depression, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>[i, get, so, nervous, even, thinking, about, t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>[i, lost, my, blinders, #panic]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>[i, feel, like, i, am, drowning, #depression, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>[this, is, the, scariest, american, horror, st...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>21142</td>\n",
       "      <td>[pull, over, #tonight, and, make, your, car, #...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>21143</td>\n",
       "      <td>[awe, aint, he, a, sweetheart, hes, adorable]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>21144</td>\n",
       "      <td>[just, had, a, steak, pie, supper]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>21145</td>\n",
       "      <td>[awe, thank, you, so, much, love]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>21146</td>\n",
       "      <td>[omg, he, kissed, her, #, w]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1147 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              tweet emotion  score\n",
       "0     20000  [i, feel, like, i, am, drowning, #depression, ...    fear  0.979\n",
       "1     20001  [i, get, so, nervous, even, thinking, about, t...    fear  0.979\n",
       "2     20002                    [i, lost, my, blinders, #panic]    fear  0.975\n",
       "3     20003  [i, feel, like, i, am, drowning, #depression, ...    fear  0.938\n",
       "4     20004  [this, is, the, scariest, american, horror, st...    fear  0.938\n",
       "...     ...                                                ...     ...    ...\n",
       "1142  21142  [pull, over, #tonight, and, make, your, car, #...    fear  0.104\n",
       "1143  21143      [awe, aint, he, a, sweetheart, hes, adorable]    fear  0.083\n",
       "1144  21144                 [just, had, a, steak, pie, supper]    fear  0.083\n",
       "1145  21145                  [awe, thank, you, so, much, love]    fear  0.062\n",
       "1146  21146                       [omg, he, kissed, her, #, w]    fear  0.062\n",
       "\n",
       "[1147 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
    "    'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your', 'so', 'this', 'all',\n",
    "    'am', 'or', 'but', 'if', 'my', 'me', 'we', 'us', 'our', 'we', 'up', 'down', 'out', 'just', 'how', 'why',\n",
    "    'when', 'where', 'here', 'there', 'about', 'more', 'most', 'some', 'any', 'few', 'many', 'much', 'not',\n",
    "    'only', 'other', 'same', 'such', 'no', 'nor', 'too', 'very', 'can', 'cannot', 'could', 'should', 'would',\n",
    "    'might', 'must', 'shall', 'will', 'isn', 'hasn', 'doesn', 'haven', 'didn', 'hadn', 'wasn', 'weren',\n",
    "    'wouldn', 'shouldn', 'ain', 'aren', 'ma'\n",
    "]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>[feel, like, drowning, #depression, #anxiety, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>[get, nervous, even, thinking, talking, wanna,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>[lost, blinders, #panic]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>[feel, like, drowning, #depression, #falure, #...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>[scariest, american, horror, story, them, im, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>21142</td>\n",
       "      <td>[pull, over, #tonight, make, car, #shake]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>21143</td>\n",
       "      <td>[awe, aint, sweetheart, hes, adorable]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>21144</td>\n",
       "      <td>[had, steak, pie, supper]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>21145</td>\n",
       "      <td>[awe, thank, love]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>21146</td>\n",
       "      <td>[omg, kissed, her]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1147 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              tweet emotion  score\n",
       "0     20000  [feel, like, drowning, #depression, #anxiety, ...    fear  0.979\n",
       "1     20001  [get, nervous, even, thinking, talking, wanna,...    fear  0.979\n",
       "2     20002                           [lost, blinders, #panic]    fear  0.975\n",
       "3     20003  [feel, like, drowning, #depression, #falure, #...    fear  0.938\n",
       "4     20004  [scariest, american, horror, story, them, im, ...    fear  0.938\n",
       "...     ...                                                ...     ...    ...\n",
       "1142  21142          [pull, over, #tonight, make, car, #shake]    fear  0.104\n",
       "1143  21143             [awe, aint, sweetheart, hes, adorable]    fear  0.083\n",
       "1144  21144                          [had, steak, pie, supper]    fear  0.083\n",
       "1145  21145                                 [awe, thank, love]    fear  0.062\n",
       "1146  21146                                 [omg, kissed, her]    fear  0.062\n",
       "\n",
       "[1147 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "model_name='bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(tweet):\n",
    "    tokenized_text = ' '.join(tweet)\n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    \n",
    "    return features\n",
    "\n",
    "df1['features'] = df1['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>[feel, like, drowning, #depression, #anxiety, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "      <td>[[0.037809342, 0.254312, -0.06298909, -0.16685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>[get, nervous, even, thinking, talking, wanna,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "      <td>[[-0.11003713, 0.12191104, 0.17953236, -0.1630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>[lost, blinders, #panic]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "      <td>[[-0.168674, 0.12842081, -0.0014389177, -0.082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>[feel, like, drowning, #depression, #falure, #...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[0.06456666, 0.26413164, -0.106887944, -0.123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>[scariest, american, horror, story, them, im, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.21259005, 0.08201837, 0.38263053, 0.04178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>21142</td>\n",
       "      <td>[pull, over, #tonight, make, car, #shake]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.104</td>\n",
       "      <td>[[-0.1298164, 0.16981113, 0.039434116, 0.13802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>21143</td>\n",
       "      <td>[awe, aint, sweetheart, hes, adorable]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.083</td>\n",
       "      <td>[[-0.15620765, 0.42569926, -0.16897485, 0.0595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>21144</td>\n",
       "      <td>[had, steak, pie, supper]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.083</td>\n",
       "      <td>[[-0.33264166, -0.13432035, -0.14950287, 0.282...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>21145</td>\n",
       "      <td>[awe, thank, love]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.062</td>\n",
       "      <td>[[-0.10937966, 0.33537936, 0.05516939, -0.0624...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>21146</td>\n",
       "      <td>[omg, kissed, her]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.062</td>\n",
       "      <td>[[-0.31615663, 0.40154505, 0.1087748, 0.316638...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1147 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              tweet emotion  score  \\\n",
       "0     20000  [feel, like, drowning, #depression, #anxiety, ...    fear  0.979   \n",
       "1     20001  [get, nervous, even, thinking, talking, wanna,...    fear  0.979   \n",
       "2     20002                           [lost, blinders, #panic]    fear  0.975   \n",
       "3     20003  [feel, like, drowning, #depression, #falure, #...    fear  0.938   \n",
       "4     20004  [scariest, american, horror, story, them, im, ...    fear  0.938   \n",
       "...     ...                                                ...     ...    ...   \n",
       "1142  21142          [pull, over, #tonight, make, car, #shake]    fear  0.104   \n",
       "1143  21143             [awe, aint, sweetheart, hes, adorable]    fear  0.083   \n",
       "1144  21144                          [had, steak, pie, supper]    fear  0.083   \n",
       "1145  21145                                 [awe, thank, love]    fear  0.062   \n",
       "1146  21146                                 [omg, kissed, her]    fear  0.062   \n",
       "\n",
       "                                               features  \n",
       "0     [[0.037809342, 0.254312, -0.06298909, -0.16685...  \n",
       "1     [[-0.11003713, 0.12191104, 0.17953236, -0.1630...  \n",
       "2     [[-0.168674, 0.12842081, -0.0014389177, -0.082...  \n",
       "3     [[0.06456666, 0.26413164, -0.106887944, -0.123...  \n",
       "4     [[-0.21259005, 0.08201837, 0.38263053, 0.04178...  \n",
       "...                                                 ...  \n",
       "1142  [[-0.1298164, 0.16981113, 0.039434116, 0.13802...  \n",
       "1143  [[-0.15620765, 0.42569926, -0.16897485, 0.0595...  \n",
       "1144  [[-0.33264166, -0.13432035, -0.14950287, 0.282...  \n",
       "1145  [[-0.10937966, 0.33537936, 0.05516939, -0.0624...  \n",
       "1146  [[-0.31615663, 0.40154505, 0.1087748, 0.316638...  \n",
       "\n",
       "[1147 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>[feel, like, drowning, #depression, #anxiety, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "      <td>[[0.037809342, 0.254312, -0.06298909, -0.16685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>[get, nervous, even, thinking, talking, wanna,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.979</td>\n",
       "      <td>[[-0.11003713, 0.12191104, 0.17953236, -0.1630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>[lost, blinders, #panic]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.975</td>\n",
       "      <td>[[-0.168674, 0.12842081, -0.0014389177, -0.082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>[feel, like, drowning, #depression, #falure, #...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[0.06456666, 0.26413164, -0.106887944, -0.123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>[scariest, american, horror, story, them, im, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.21259005, 0.08201837, 0.38263053, 0.04178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20005</td>\n",
       "      <td>[nearly, started, crying, having, full, panic,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.6936238, -0.16869353, 0.12774356, -0.1491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20006</td>\n",
       "      <td>[have, finally, tell, therapist, sexuality, la...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.2576109, 0.28046265, -0.046328988, -0.192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20007</td>\n",
       "      <td>[dont, think, ive, ever, moved, fast, panic, l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.27630442, 0.398449, -0.18360381, -0.18951...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20008</td>\n",
       "      <td>[bus, car, crash, im, still, shaking, bit, wee...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.30670476, 0.43248904, -0.079600625, -0.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20009</td>\n",
       "      <td>[bus, car, crash, im, still, shaking, bit, wee...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.920</td>\n",
       "      <td>[[-0.23693994, 0.47858533, -0.1310488, -0.0193...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                              tweet emotion  score  \\\n",
       "0  20000  [feel, like, drowning, #depression, #anxiety, ...    fear  0.979   \n",
       "1  20001  [get, nervous, even, thinking, talking, wanna,...    fear  0.979   \n",
       "2  20002                           [lost, blinders, #panic]    fear  0.975   \n",
       "3  20003  [feel, like, drowning, #depression, #falure, #...    fear  0.938   \n",
       "4  20004  [scariest, american, horror, story, them, im, ...    fear  0.938   \n",
       "5  20005  [nearly, started, crying, having, full, panic,...    fear  0.938   \n",
       "6  20006  [have, finally, tell, therapist, sexuality, la...    fear  0.938   \n",
       "7  20007  [dont, think, ive, ever, moved, fast, panic, l...    fear  0.938   \n",
       "8  20008  [bus, car, crash, im, still, shaking, bit, wee...    fear  0.938   \n",
       "9  20009  [bus, car, crash, im, still, shaking, bit, wee...    fear  0.920   \n",
       "\n",
       "                                            features  \n",
       "0  [[0.037809342, 0.254312, -0.06298909, -0.16685...  \n",
       "1  [[-0.11003713, 0.12191104, 0.17953236, -0.1630...  \n",
       "2  [[-0.168674, 0.12842081, -0.0014389177, -0.082...  \n",
       "3  [[0.06456666, 0.26413164, -0.106887944, -0.123...  \n",
       "4  [[-0.21259005, 0.08201837, 0.38263053, 0.04178...  \n",
       "5  [[-0.6936238, -0.16869353, 0.12774356, -0.1491...  \n",
       "6  [[-0.2576109, 0.28046265, -0.046328988, -0.192...  \n",
       "7  [[-0.27630442, 0.398449, -0.18360381, -0.18951...  \n",
       "8  [[-0.30670476, 0.43248904, -0.079600625, -0.24...  \n",
       "9  [[-0.23693994, 0.47858533, -0.1310488, -0.0193...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "features = df1['features'].tolist()\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "padded_df = df1.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (1147, 41, 768)\n"
     ]
    }
   ],
   "source": [
    "X = np.stack(padded_df['features'])\n",
    "print('Input feature shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1147, 41, 768)\n",
      "Output shape: (1147,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(padded_df['score']) \n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (1147, 41 * 768)) \n",
    "y = np.reshape(y, (1147,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 31488)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df1['score'].copy()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 31488)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = len(max(X, key=len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8096)              254934944 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4048)              32776656  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2024)              8195176   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1012)              2049300   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1012)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 506)               512578    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 506)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               64896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298,537,711\n",
      "Trainable params: 298,537,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8096, input_shape=(31488,), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(4048, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2024, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1012, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(506, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='mean_squared_error', patience=1, mode='min')\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 31488)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tweet'] = df1['tweet'].apply(lambda tokens: ' '.join(tokens))\n",
    "array = df1['tweet'].values\n",
    "tensor = tf.convert_to_tensor(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 31488)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43/43 [==============================] - 213s 4s/step - loss: 48.8578 - mean_squared_error: 1.0132\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 168s 4s/step - loss: 17.0370 - mean_squared_error: 0.0758\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 186s 4s/step - loss: 10.7044 - mean_squared_error: 0.0340\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 185s 4s/step - loss: 7.6491 - mean_squared_error: 0.0304\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 179s 4s/step - loss: 5.8212 - mean_squared_error: 0.0302\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 183s 4s/step - loss: 4.6097 - mean_squared_error: 0.0276\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 180s 4s/step - loss: 3.7615 - mean_squared_error: 0.0302\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=27, epochs=10, shuffle=True, verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emointjoy.h5','/Home')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('emointjoy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold= pd.read_csv(\"Desktop/emoint tweet/fear-ratings-0to1.dev.gold.txt\", delimiter='\\t', header=None)\n",
    "gold.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21147</td>\n",
       "      <td>I know this is going to be one of those nights...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21148</td>\n",
       "      <td>This is #horrible: Lewis Dunk has begun networ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21149</td>\n",
       "      <td>@JeffersonLake speaking of ex cobblers, saw Ri...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21150</td>\n",
       "      <td>@1johndes ball watching &amp;amp; Rojo'd header wa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21151</td>\n",
       "      <td>Really.....#Jumanji 2....w/ The Rock, Jack Bla...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21252</td>\n",
       "      <td>Staff on @ryainair FR1005. Asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>21253</td>\n",
       "      <td>Staff on @ryainair FR1005. Asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21254</td>\n",
       "      <td>An adviser to the #European #Unionâ€™s top #cour...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21255</td>\n",
       "      <td>So about 18mths ago i signed up to @Lumo_Energ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21256</td>\n",
       "      <td>So about 18mths ago i signed up to @Lumo_Energ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    21147  I know this is going to be one of those nights...    fear  0.771\n",
       "1    21148  This is #horrible: Lewis Dunk has begun networ...    fear  0.479\n",
       "2    21149  @JeffersonLake speaking of ex cobblers, saw Ri...    fear  0.417\n",
       "3    21150  @1johndes ball watching &amp; Rojo'd header wa...    fear  0.475\n",
       "4    21151  Really.....#Jumanji 2....w/ The Rock, Jack Bla...    fear  0.542\n",
       "..     ...                                                ...     ...    ...\n",
       "105  21252  Staff on @ryainair FR1005. Asked for info and ...    fear  0.312\n",
       "106  21253  Staff on @ryainair FR1005. Asked for info and ...    fear  0.271\n",
       "107  21254  An adviser to the #European #Unionâ€™s top #cour...    fear  0.500\n",
       "108  21255  So about 18mths ago i signed up to @Lumo_Energ...    fear  0.479\n",
       "109  21256  So about 18mths ago i signed up to @Lumo_Energ...    fear  0.271\n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "gold['tweet'] = gold['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21147</td>\n",
       "      <td>i know this is going to be one of those nights...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21148</td>\n",
       "      <td>this is #horrible: lewis dunk has begun networ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21149</td>\n",
       "      <td>@jeffersonlake speaking of ex cobblers, saw ri...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21150</td>\n",
       "      <td>@1johndes ball watching &amp;amp; rojo'd header wa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21151</td>\n",
       "      <td>really.....#jumanji 2....w/ the rock, jack bla...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21252</td>\n",
       "      <td>staff on @ryainair fr1005. asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>21253</td>\n",
       "      <td>staff on @ryainair fr1005. asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21254</td>\n",
       "      <td>an adviser to the #european #unionâ€™s top #cour...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21255</td>\n",
       "      <td>so about 18mths ago i signed up to @lumo_energ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21256</td>\n",
       "      <td>so about 18mths ago i signed up to @lumo_energ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    21147  i know this is going to be one of those nights...    fear  0.771\n",
       "1    21148  this is #horrible: lewis dunk has begun networ...    fear  0.479\n",
       "2    21149  @jeffersonlake speaking of ex cobblers, saw ri...    fear  0.417\n",
       "3    21150  @1johndes ball watching &amp; rojo'd header wa...    fear  0.475\n",
       "4    21151  really.....#jumanji 2....w/ the rock, jack bla...    fear  0.542\n",
       "..     ...                                                ...     ...    ...\n",
       "105  21252  staff on @ryainair fr1005. asked for info and ...    fear  0.312\n",
       "106  21253  staff on @ryainair fr1005. asked for info and ...    fear  0.271\n",
       "107  21254  an adviser to the #european #unionâ€™s top #cour...    fear  0.500\n",
       "108  21255  so about 18mths ago i signed up to @lumo_energ...    fear  0.479\n",
       "109  21256  so about 18mths ago i signed up to @lumo_energ...    fear  0.271\n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21147</td>\n",
       "      <td>i know this is going to be one of those nights...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21148</td>\n",
       "      <td>this is #horrible: lewis dunk has begun networ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21149</td>\n",
       "      <td>speaking of ex cobblers, saw ricky holmes at ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21150</td>\n",
       "      <td>ball watching &amp;amp; rojo'd header was equally...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21151</td>\n",
       "      <td>really.....#jumanji 2....w/ the rock, jack bla...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21252</td>\n",
       "      <td>staff on  fr1005. asked for info and told to l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>21253</td>\n",
       "      <td>staff on  fr1005. asked for info and told to l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21254</td>\n",
       "      <td>an adviser to the #european #unionâ€™s top #cour...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21255</td>\n",
       "      <td>so about 18mths ago i signed up to  for their ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21256</td>\n",
       "      <td>so about 18mths ago i signed up to  for their ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    21147  i know this is going to be one of those nights...    fear  0.771\n",
       "1    21148  this is #horrible: lewis dunk has begun networ...    fear  0.479\n",
       "2    21149   speaking of ex cobblers, saw ricky holmes at ...    fear  0.417\n",
       "3    21150   ball watching &amp; rojo'd header was equally...    fear  0.475\n",
       "4    21151  really.....#jumanji 2....w/ the rock, jack bla...    fear  0.542\n",
       "..     ...                                                ...     ...    ...\n",
       "105  21252  staff on  fr1005. asked for info and told to l...    fear  0.312\n",
       "106  21253  staff on  fr1005. asked for info and told to l...    fear  0.271\n",
       "107  21254  an adviser to the #european #unionâ€™s top #cour...    fear  0.500\n",
       "108  21255  so about 18mths ago i signed up to  for their ...    fear  0.479\n",
       "109  21256  so about 18mths ago i signed up to  for their ...    fear  0.271\n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(remove_mentions)\n",
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gold(gold):\n",
    "    gold  = re.sub(r'[^\\w\\s#@]', '', gold ) \n",
    "    gold  = re.sub(r'\\d+', '', gold)  \n",
    "    gold  = re.sub(r'\\s+', ' ', gold).strip()\n",
    "    return gold\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(clean_gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21147</td>\n",
       "      <td>i know this is going to be one of those nights...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21148</td>\n",
       "      <td>this is #horrible lewis dunk has begun network...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21149</td>\n",
       "      <td>speaking of ex cobblers saw ricky holmes at ch...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21150</td>\n",
       "      <td>ball watching amp rojod header was equally dre...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21151</td>\n",
       "      <td>really#jumanji w the rock jack black and kevin...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21252</td>\n",
       "      <td>staff on fr asked for info and told to look on...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>21253</td>\n",
       "      <td>staff on fr asked for info and told to look on...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21254</td>\n",
       "      <td>an adviser to the #european #unions top #court...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21255</td>\n",
       "      <td>so about mths ago i signed up to for their vel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21256</td>\n",
       "      <td>so about mths ago i signed up to for their vel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    21147  i know this is going to be one of those nights...    fear  0.771\n",
       "1    21148  this is #horrible lewis dunk has begun network...    fear  0.479\n",
       "2    21149  speaking of ex cobblers saw ricky holmes at ch...    fear  0.417\n",
       "3    21150  ball watching amp rojod header was equally dre...    fear  0.475\n",
       "4    21151  really#jumanji w the rock jack black and kevin...    fear  0.542\n",
       "..     ...                                                ...     ...    ...\n",
       "105  21252  staff on fr asked for info and told to look on...    fear  0.312\n",
       "106  21253  staff on fr asked for info and told to look on...    fear  0.271\n",
       "107  21254  an adviser to the #european #unions top #court...    fear  0.500\n",
       "108  21255  so about mths ago i signed up to for their vel...    fear  0.479\n",
       "109  21256  so about mths ago i signed up to for their vel...    fear  0.271\n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji(tweet):\n",
    "    gold = emoji.demojize(tweet)\n",
    "    return gold\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21147</td>\n",
       "      <td>[i, know, this, is, going, to, be, one, of, th...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21148</td>\n",
       "      <td>[this, is, #horrible, lewis, dunk, has, begun,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21149</td>\n",
       "      <td>[speaking, of, ex, cobblers, saw, ricky, holme...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21150</td>\n",
       "      <td>[ball, watching, amp, rojod, header, was, equa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21151</td>\n",
       "      <td>[really, #jumanji, w, the, rock, jack, black, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21252</td>\n",
       "      <td>[staff, on, fr, asked, for, info, and, told, t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>21253</td>\n",
       "      <td>[staff, on, fr, asked, for, info, and, told, t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21254</td>\n",
       "      <td>[an, adviser, to, the, #european, #unions, top...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21255</td>\n",
       "      <td>[so, about, mths, ago, i, signed, up, to, for,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21256</td>\n",
       "      <td>[so, about, mths, ago, i, signed, up, to, for,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    21147  [i, know, this, is, going, to, be, one, of, th...    fear  0.771\n",
       "1    21148  [this, is, #horrible, lewis, dunk, has, begun,...    fear  0.479\n",
       "2    21149  [speaking, of, ex, cobblers, saw, ricky, holme...    fear  0.417\n",
       "3    21150  [ball, watching, amp, rojod, header, was, equa...    fear  0.475\n",
       "4    21151  [really, #jumanji, w, the, rock, jack, black, ...    fear  0.542\n",
       "..     ...                                                ...     ...    ...\n",
       "105  21252  [staff, on, fr, asked, for, info, and, told, t...    fear  0.312\n",
       "106  21253  [staff, on, fr, asked, for, info, and, told, t...    fear  0.271\n",
       "107  21254  [an, adviser, to, the, #european, #unions, top...    fear  0.500\n",
       "108  21255  [so, about, mths, ago, i, signed, up, to, for,...    fear  0.479\n",
       "109  21256  [so, about, mths, ago, i, signed, up, to, for,...    fear  0.271\n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
    "    'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your', 'so', 'this', 'all',\n",
    "    'am', 'or', 'but', 'if', 'my', 'me', 'we', 'us', 'our', 'we', 'up', 'down', 'out', 'just', 'how', 'why',\n",
    "    'when', 'where', 'here', 'there', 'about', 'more', 'most', 'some', 'any', 'few', 'many', 'much', 'not',\n",
    "    'only', 'other', 'same', 'such', 'no', 'nor', 'too', 'very', 'can', 'cannot', 'could', 'should', 'would',\n",
    "    'might', 'must', 'shall', 'will', 'isn', 'hasn', 'doesn', 'haven', 'didn', 'hadn', 'wasn', 'weren',\n",
    "    'wouldn', 'shouldn', 'ain', 'aren', 'ma'\n",
    "]\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21147</td>\n",
       "      <td>[know, going, one, those, nights, takes, act, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21148</td>\n",
       "      <td>[#horrible, lewis, dunk, begun, networking, ne...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21149</td>\n",
       "      <td>[speaking, ex, cobblers, saw, ricky, holmes, c...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21150</td>\n",
       "      <td>[ball, watching, amp, rojod, header, equally, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21151</td>\n",
       "      <td>[really, #jumanji, rock, jack, black, kevin, h...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21252</td>\n",
       "      <td>[staff, fr, asked, info, told, look, online, g...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>21253</td>\n",
       "      <td>[staff, fr, asked, info, told, look, online, g...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21254</td>\n",
       "      <td>[adviser, #european, #unions, top, #court, sai...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21255</td>\n",
       "      <td>[mths, ago, signed, their, velocity, ff, deal,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21256</td>\n",
       "      <td>[mths, ago, signed, their, velocity, ff, deal,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    21147  [know, going, one, those, nights, takes, act, ...    fear  0.771\n",
       "1    21148  [#horrible, lewis, dunk, begun, networking, ne...    fear  0.479\n",
       "2    21149  [speaking, ex, cobblers, saw, ricky, holmes, c...    fear  0.417\n",
       "3    21150  [ball, watching, amp, rojod, header, equally, ...    fear  0.475\n",
       "4    21151  [really, #jumanji, rock, jack, black, kevin, h...    fear  0.542\n",
       "..     ...                                                ...     ...    ...\n",
       "105  21252  [staff, fr, asked, info, told, look, online, g...    fear  0.312\n",
       "106  21253  [staff, fr, asked, info, told, look, online, g...    fear  0.271\n",
       "107  21254  [adviser, #european, #unions, top, #court, sai...    fear  0.500\n",
       "108  21255  [mths, ago, signed, their, velocity, ff, deal,...    fear  0.479\n",
       "109  21256  [mths, ago, signed, their, velocity, ff, deal,...    fear  0.271\n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(tweet):\n",
    "    tokenized_text = ' '.join(tweet)\n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    return features\n",
    "\n",
    "\n",
    "gold['features'] = gold['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 768)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold[\"features\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "features =gold['features'].tolist()\n",
    "\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "\n",
    "padded_df = gold.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (110, 40, 768)\n"
     ]
    }
   ],
   "source": [
    "X_gold= np.stack(padded_df['features'])\n",
    "print('Input feature shape:', X_gold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_length = 41\n",
    "\n",
    "padded_gold_data = pad_sequences(X_gold, maxlen=max_sequence_length, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(padded_gold_data, (110, 41 * 768))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_features = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 31488)\n"
     ]
    }
   ],
   "source": [
    "print(gold_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 173ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = loaded_model.predict(gold_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5156709 ]\n",
      " [0.46329266]\n",
      " [0.48386526]\n",
      " [0.48698324]\n",
      " [0.4597918 ]\n",
      " [0.5117012 ]\n",
      " [0.55958515]\n",
      " [0.49263036]\n",
      " [0.5181461 ]\n",
      " [0.5651391 ]\n",
      " [0.5719571 ]\n",
      " [0.5850078 ]\n",
      " [0.52914345]\n",
      " [0.46887633]\n",
      " [0.49627924]\n",
      " [0.51505166]\n",
      " [0.46910596]\n",
      " [0.61082125]\n",
      " [0.5784122 ]\n",
      " [0.562088  ]\n",
      " [0.42101935]\n",
      " [0.4267837 ]\n",
      " [0.49372813]\n",
      " [0.5099395 ]\n",
      " [0.4629725 ]\n",
      " [0.44091418]\n",
      " [0.61902326]\n",
      " [0.51560116]\n",
      " [0.4711641 ]\n",
      " [0.51210064]\n",
      " [0.47374916]\n",
      " [0.43829653]\n",
      " [0.45188868]\n",
      " [0.4966091 ]\n",
      " [0.47757944]\n",
      " [0.5735184 ]\n",
      " [0.5487175 ]\n",
      " [0.5747378 ]\n",
      " [0.5403084 ]\n",
      " [0.52733374]\n",
      " [0.50542456]\n",
      " [0.563625  ]\n",
      " [0.47232357]\n",
      " [0.5260281 ]\n",
      " [0.46255192]\n",
      " [0.5965444 ]\n",
      " [0.5484059 ]\n",
      " [0.6394912 ]\n",
      " [0.4945289 ]\n",
      " [0.51672506]\n",
      " [0.49168605]\n",
      " [0.49469286]\n",
      " [0.6925488 ]\n",
      " [0.4873956 ]\n",
      " [0.4502115 ]\n",
      " [0.44138297]\n",
      " [0.4800793 ]\n",
      " [0.5998421 ]\n",
      " [0.5758794 ]\n",
      " [0.47859108]\n",
      " [0.56929463]\n",
      " [0.40510198]\n",
      " [0.40537232]\n",
      " [0.4268184 ]\n",
      " [0.4473968 ]\n",
      " [0.47793162]\n",
      " [0.46722105]\n",
      " [0.5847932 ]\n",
      " [0.49396613]\n",
      " [0.50410324]\n",
      " [0.47221458]\n",
      " [0.51890415]\n",
      " [0.48590845]\n",
      " [0.5442083 ]\n",
      " [0.49477893]\n",
      " [0.47691122]\n",
      " [0.5404349 ]\n",
      " [0.49944755]\n",
      " [0.53355956]\n",
      " [0.4894894 ]\n",
      " [0.48108333]\n",
      " [0.3697067 ]\n",
      " [0.42718366]\n",
      " [0.49210048]\n",
      " [0.36114293]\n",
      " [0.53387856]\n",
      " [0.53648746]\n",
      " [0.5082978 ]\n",
      " [0.42616746]\n",
      " [0.5567318 ]\n",
      " [0.6163031 ]\n",
      " [0.34402713]\n",
      " [0.4573421 ]\n",
      " [0.48993474]\n",
      " [0.41869158]\n",
      " [0.4313248 ]\n",
      " [0.50587386]\n",
      " [0.4675902 ]\n",
      " [0.51182526]\n",
      " [0.48454627]\n",
      " [0.485465  ]\n",
      " [0.4145124 ]\n",
      " [0.4712085 ]\n",
      " [0.49608886]\n",
      " [0.49263173]\n",
      " [0.4433105 ]\n",
      " [0.4818247 ]\n",
      " [0.5790781 ]\n",
      " [0.47399122]\n",
      " [0.46507964]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold['prediction']=pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21147</td>\n",
       "      <td>[know, going, one, those, nights, takes, act, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "      <td>[[-0.20082852, 0.23499466, 0.26666716, -0.2509...</td>\n",
       "      <td>0.515671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21148</td>\n",
       "      <td>[#horrible, lewis, dunk, begun, networking, ne...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[[0.0052761673, 0.09974696, 0.24677433, 0.1428...</td>\n",
       "      <td>0.463293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21149</td>\n",
       "      <td>[speaking, ex, cobblers, saw, ricky, holmes, c...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[[-0.1114298, 0.11400322, 0.12179627, -0.36932...</td>\n",
       "      <td>0.483865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21150</td>\n",
       "      <td>[ball, watching, amp, rojod, header, equally, ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.475</td>\n",
       "      <td>[[-0.43671992, 0.057505418, -0.19090301, -0.25...</td>\n",
       "      <td>0.486983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21151</td>\n",
       "      <td>[really, #jumanji, rock, jack, black, kevin, h...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "      <td>[[-0.33436796, 0.09009981, -0.15924482, -0.018...</td>\n",
       "      <td>0.459792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21252</td>\n",
       "      <td>[staff, fr, asked, info, told, look, online, g...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[[-0.1426141, 0.0785741, 0.31430638, -0.066660...</td>\n",
       "      <td>0.443310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>21253</td>\n",
       "      <td>[staff, fr, asked, info, told, look, online, g...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[[-0.16974156, 0.0924546, 0.22362891, -0.04701...</td>\n",
       "      <td>0.481825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21254</td>\n",
       "      <td>[adviser, #european, #unions, top, #court, sai...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[[-0.6108634, 0.1406612, -0.09995471, -0.29053...</td>\n",
       "      <td>0.579078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21255</td>\n",
       "      <td>[mths, ago, signed, their, velocity, ff, deal,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[[-0.73062104, 0.021704849, 0.4836302, 0.01967...</td>\n",
       "      <td>0.473991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21256</td>\n",
       "      <td>[mths, ago, signed, their, velocity, ff, deal,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[[-0.65487427, 0.06511383, 0.3699499, -0.06512...</td>\n",
       "      <td>0.465080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score  \\\n",
       "0    21147  [know, going, one, those, nights, takes, act, ...    fear  0.771   \n",
       "1    21148  [#horrible, lewis, dunk, begun, networking, ne...    fear  0.479   \n",
       "2    21149  [speaking, ex, cobblers, saw, ricky, holmes, c...    fear  0.417   \n",
       "3    21150  [ball, watching, amp, rojod, header, equally, ...    fear  0.475   \n",
       "4    21151  [really, #jumanji, rock, jack, black, kevin, h...    fear  0.542   \n",
       "..     ...                                                ...     ...    ...   \n",
       "105  21252  [staff, fr, asked, info, told, look, online, g...    fear  0.312   \n",
       "106  21253  [staff, fr, asked, info, told, look, online, g...    fear  0.271   \n",
       "107  21254  [adviser, #european, #unions, top, #court, sai...    fear  0.500   \n",
       "108  21255  [mths, ago, signed, their, velocity, ff, deal,...    fear  0.479   \n",
       "109  21256  [mths, ago, signed, their, velocity, ff, deal,...    fear  0.271   \n",
       "\n",
       "                                              features  prediction  \n",
       "0    [[-0.20082852, 0.23499466, 0.26666716, -0.2509...    0.515671  \n",
       "1    [[0.0052761673, 0.09974696, 0.24677433, 0.1428...    0.463293  \n",
       "2    [[-0.1114298, 0.11400322, 0.12179627, -0.36932...    0.483865  \n",
       "3    [[-0.43671992, 0.057505418, -0.19090301, -0.25...    0.486983  \n",
       "4    [[-0.33436796, 0.09009981, -0.15924482, -0.018...    0.459792  \n",
       "..                                                 ...         ...  \n",
       "105  [[-0.1426141, 0.0785741, 0.31430638, -0.066660...    0.443310  \n",
       "106  [[-0.16974156, 0.0924546, 0.22362891, -0.04701...    0.481825  \n",
       "107  [[-0.6108634, 0.1406612, -0.09995471, -0.29053...    0.579078  \n",
       "108  [[-0.73062104, 0.021704849, 0.4836302, 0.01967...    0.473991  \n",
       "109  [[-0.65487427, 0.06511383, 0.3699499, -0.06512...    0.465080  \n",
       "\n",
       "[110 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square Error: 0.033003402965125085\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(gold['score'], gold['prediction'])\n",
    "print(\"Mean square Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"Desktop/emoint tweet/fear-ratings-0to1.test.target.txt\", delimiter='\\t', header=None)\n",
    "test.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "test['tweet'] = test['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21257</td>\n",
       "      <td>#matthew 25; 1-13\\ncould somebody shoot a #vid...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21258</td>\n",
       "      <td>which really sucks because typing on a mobil...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21259</td>\n",
       "      <td>be #afraid of the #quiet ones they are the one...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21260</td>\n",
       "      <td>he's a horrible person and now i gag when i s...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21261</td>\n",
       "      <td>what we fear doing most is usually what we mos...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>22247</td>\n",
       "      <td>9 -9 vs atlanta this yr, 2 - 11 vs rockies an...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>22248</td>\n",
       "      <td>i'm shaking now.</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>22249</td>\n",
       "      <td>me: are you guys dating yet #trans #nervous #b...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>22250</td>\n",
       "      <td>she: why are you listening to the eurythmics?\\...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>22251</td>\n",
       "      <td>and claimed that all of the same things could ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion score\n",
       "0    21257  #matthew 25; 1-13\\ncould somebody shoot a #vid...    fear  NONE\n",
       "1    21258    which really sucks because typing on a mobil...    fear  NONE\n",
       "2    21259  be #afraid of the #quiet ones they are the one...    fear  NONE\n",
       "3    21260   he's a horrible person and now i gag when i s...    fear  NONE\n",
       "4    21261  what we fear doing most is usually what we mos...    fear  NONE\n",
       "..     ...                                                ...     ...   ...\n",
       "990  22247   9 -9 vs atlanta this yr, 2 - 11 vs rockies an...    fear  NONE\n",
       "991  22248                                   i'm shaking now.    fear  NONE\n",
       "992  22249  me: are you guys dating yet #trans #nervous #b...    fear  NONE\n",
       "993  22250  she: why are you listening to the eurythmics?\\...    fear  NONE\n",
       "994  22251  and claimed that all of the same things could ...    fear  NONE\n",
       "\n",
       "[995 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(remove_mentions)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_test(test):\n",
    "    test  = re.sub(r'[^\\w\\s#@]', '', test ) \n",
    "    test  = re.sub(r'\\d+', '', test)  \n",
    "    test  = re.sub(r'\\s+', ' ', test).strip()\n",
    "    return test\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(clean_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
    "    'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your', 'so', 'this', 'all',\n",
    "    'am', 'or', 'but', 'if', 'my', 'me', 'we', 'us', 'our', 'we', 'up', 'down', 'out', 'just', 'how', 'why',\n",
    "    'when', 'where', 'here', 'there', 'about', 'more', 'most', 'some', 'any', 'few', 'many', 'much', 'not',\n",
    "    'only', 'other', 'same', 'such', 'no', 'nor', 'too', 'very', 'can', 'cannot', 'could', 'should', 'would',\n",
    "    'might', 'must', 'shall', 'will', 'isn', 'hasn', 'doesn', 'haven', 'didn', 'hadn', 'wasn', 'weren',\n",
    "    'wouldn', 'shouldn', 'ain', 'aren', 'ma'\n",
    "]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(tweet):\n",
    "    tokenized_text = ' '.join(tweet)\n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    return features\n",
    "\n",
    "\n",
    "test['features'] = test['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 768)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"features\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "features =test['features'].tolist()\n",
    "\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "\n",
    "padded_df = test.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (995, 38, 768)\n"
     ]
    }
   ],
   "source": [
    "X_test= np.stack(padded_df['features'])\n",
    "print('Input feature shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 41, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_length = 41\n",
    "truncated_test_data = pad_sequences(X_test, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "print(truncated_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(truncated_test_data, (995, 41 * 768)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 31488)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 134ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = loaded_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50026184]\n",
      " [0.5481893 ]\n",
      " [0.5215363 ]\n",
      " [0.4408408 ]\n",
      " [0.563223  ]\n",
      " [0.5123622 ]\n",
      " [0.5534655 ]\n",
      " [0.5848606 ]\n",
      " [0.5374498 ]\n",
      " [0.543158  ]\n",
      " [0.6040136 ]\n",
      " [0.55956805]\n",
      " [0.5181162 ]\n",
      " [0.5662841 ]\n",
      " [0.5511442 ]\n",
      " [0.53213876]\n",
      " [0.5410506 ]\n",
      " [0.4854576 ]\n",
      " [0.4529214 ]\n",
      " [0.4973553 ]\n",
      " [0.5497619 ]\n",
      " [0.4713636 ]\n",
      " [0.5279356 ]\n",
      " [0.54562026]\n",
      " [0.52188855]\n",
      " [0.537604  ]\n",
      " [0.4972305 ]\n",
      " [0.58875924]\n",
      " [0.5560321 ]\n",
      " [0.45461798]\n",
      " [0.45070103]\n",
      " [0.49043754]\n",
      " [0.4762447 ]\n",
      " [0.4232683 ]\n",
      " [0.47513476]\n",
      " [0.52878857]\n",
      " [0.5637623 ]\n",
      " [0.7293352 ]\n",
      " [0.5697651 ]\n",
      " [0.52456087]\n",
      " [0.4633235 ]\n",
      " [0.46756002]\n",
      " [0.51122046]\n",
      " [0.5574097 ]\n",
      " [0.42910868]\n",
      " [0.4861828 ]\n",
      " [0.419192  ]\n",
      " [0.50288814]\n",
      " [0.5670861 ]\n",
      " [0.4938065 ]\n",
      " [0.48123902]\n",
      " [0.5124925 ]\n",
      " [0.5535056 ]\n",
      " [0.51496863]\n",
      " [0.57860893]\n",
      " [0.5478402 ]\n",
      " [0.5001272 ]\n",
      " [0.5517594 ]\n",
      " [0.5204648 ]\n",
      " [0.45577502]\n",
      " [0.41979095]\n",
      " [0.489095  ]\n",
      " [0.5100465 ]\n",
      " [0.51027256]\n",
      " [0.6097312 ]\n",
      " [0.5569446 ]\n",
      " [0.46642476]\n",
      " [0.3641048 ]\n",
      " [0.42972398]\n",
      " [0.5477738 ]\n",
      " [0.53355587]\n",
      " [0.5021558 ]\n",
      " [0.61802256]\n",
      " [0.47571054]\n",
      " [0.47774816]\n",
      " [0.5022841 ]\n",
      " [0.55036896]\n",
      " [0.5599985 ]\n",
      " [0.5026285 ]\n",
      " [0.42272434]\n",
      " [0.50064874]\n",
      " [0.5486406 ]\n",
      " [0.5331601 ]\n",
      " [0.47923398]\n",
      " [0.4549035 ]\n",
      " [0.4349103 ]\n",
      " [0.5867812 ]\n",
      " [0.52699685]\n",
      " [0.4918208 ]\n",
      " [0.4954478 ]\n",
      " [0.5883531 ]\n",
      " [0.5401514 ]\n",
      " [0.5117196 ]\n",
      " [0.50200176]\n",
      " [0.56853825]\n",
      " [0.5179327 ]\n",
      " [0.46528572]\n",
      " [0.49675053]\n",
      " [0.4872259 ]\n",
      " [0.49567547]\n",
      " [0.3724922 ]\n",
      " [0.5283637 ]\n",
      " [0.57812774]\n",
      " [0.49253252]\n",
      " [0.56474525]\n",
      " [0.52483946]\n",
      " [0.476826  ]\n",
      " [0.45071086]\n",
      " [0.4956916 ]\n",
      " [0.48174948]\n",
      " [0.5625797 ]\n",
      " [0.43436345]\n",
      " [0.47514877]\n",
      " [0.51794654]\n",
      " [0.44213292]\n",
      " [0.50159   ]\n",
      " [0.49854594]\n",
      " [0.5466028 ]\n",
      " [0.59545094]\n",
      " [0.49988025]\n",
      " [0.50141656]\n",
      " [0.5489182 ]\n",
      " [0.5033735 ]\n",
      " [0.4274963 ]\n",
      " [0.46844858]\n",
      " [0.46691453]\n",
      " [0.50514215]\n",
      " [0.51704276]\n",
      " [0.50069284]\n",
      " [0.42628413]\n",
      " [0.48040178]\n",
      " [0.47072926]\n",
      " [0.41183525]\n",
      " [0.45078507]\n",
      " [0.5161894 ]\n",
      " [0.4876569 ]\n",
      " [0.56865364]\n",
      " [0.53902864]\n",
      " [0.48769107]\n",
      " [0.41628963]\n",
      " [0.44094795]\n",
      " [0.5106397 ]\n",
      " [0.5742982 ]\n",
      " [0.503072  ]\n",
      " [0.5509837 ]\n",
      " [0.5320665 ]\n",
      " [0.54576236]\n",
      " [0.45192325]\n",
      " [0.5106455 ]\n",
      " [0.50776476]\n",
      " [0.48764682]\n",
      " [0.45911023]\n",
      " [0.57307154]\n",
      " [0.59741604]\n",
      " [0.4641555 ]\n",
      " [0.4416586 ]\n",
      " [0.45950732]\n",
      " [0.4796654 ]\n",
      " [0.44270155]\n",
      " [0.5651895 ]\n",
      " [0.42633444]\n",
      " [0.455853  ]\n",
      " [0.47472307]\n",
      " [0.51112473]\n",
      " [0.54136175]\n",
      " [0.51738954]\n",
      " [0.4812612 ]\n",
      " [0.45426962]\n",
      " [0.4732379 ]\n",
      " [0.56419635]\n",
      " [0.56274897]\n",
      " [0.45512846]\n",
      " [0.5466873 ]\n",
      " [0.673538  ]\n",
      " [0.44354174]\n",
      " [0.45185757]\n",
      " [0.5782862 ]\n",
      " [0.5910087 ]\n",
      " [0.50249106]\n",
      " [0.46087146]\n",
      " [0.46913844]\n",
      " [0.46277404]\n",
      " [0.5278969 ]\n",
      " [0.58763814]\n",
      " [0.45389926]\n",
      " [0.4701299 ]\n",
      " [0.5653898 ]\n",
      " [0.4076238 ]\n",
      " [0.48116183]\n",
      " [0.42364794]\n",
      " [0.5227407 ]\n",
      " [0.5457049 ]\n",
      " [0.51223975]\n",
      " [0.4657649 ]\n",
      " [0.49780244]\n",
      " [0.5226033 ]\n",
      " [0.45740747]\n",
      " [0.48914653]\n",
      " [0.44389245]\n",
      " [0.5123764 ]\n",
      " [0.43002388]\n",
      " [0.59747535]\n",
      " [0.58582705]\n",
      " [0.56405866]\n",
      " [0.4378538 ]\n",
      " [0.46486288]\n",
      " [0.53377485]\n",
      " [0.541903  ]\n",
      " [0.5316347 ]\n",
      " [0.49935403]\n",
      " [0.4914847 ]\n",
      " [0.46083322]\n",
      " [0.49489826]\n",
      " [0.5787696 ]\n",
      " [0.61194533]\n",
      " [0.5022887 ]\n",
      " [0.5634336 ]\n",
      " [0.53963214]\n",
      " [0.46995935]\n",
      " [0.4624695 ]\n",
      " [0.5119373 ]\n",
      " [0.54588556]\n",
      " [0.48290476]\n",
      " [0.50372416]\n",
      " [0.52342916]\n",
      " [0.40938255]\n",
      " [0.4674983 ]\n",
      " [0.55283034]\n",
      " [0.54299575]\n",
      " [0.69052297]\n",
      " [0.6630801 ]\n",
      " [0.5705042 ]\n",
      " [0.59469235]\n",
      " [0.6172163 ]\n",
      " [0.5277131 ]\n",
      " [0.5137607 ]\n",
      " [0.5153793 ]\n",
      " [0.53218275]\n",
      " [0.46391883]\n",
      " [0.4648589 ]\n",
      " [0.4530242 ]\n",
      " [0.49140495]\n",
      " [0.4653653 ]\n",
      " [0.45252573]\n",
      " [0.55036205]\n",
      " [0.53253734]\n",
      " [0.47355387]\n",
      " [0.5779076 ]\n",
      " [0.4896572 ]\n",
      " [0.5620831 ]\n",
      " [0.5120449 ]\n",
      " [0.50814617]\n",
      " [0.46287632]\n",
      " [0.50455093]\n",
      " [0.4963053 ]\n",
      " [0.45849437]\n",
      " [0.57254785]\n",
      " [0.500117  ]\n",
      " [0.5834839 ]\n",
      " [0.5401445 ]\n",
      " [0.41876236]\n",
      " [0.5220429 ]\n",
      " [0.5006365 ]\n",
      " [0.5083401 ]\n",
      " [0.56599146]\n",
      " [0.525895  ]\n",
      " [0.4910476 ]\n",
      " [0.4627336 ]\n",
      " [0.35454708]\n",
      " [0.50789577]\n",
      " [0.4511299 ]\n",
      " [0.4027506 ]\n",
      " [0.4433071 ]\n",
      " [0.53555137]\n",
      " [0.46506336]\n",
      " [0.5802386 ]\n",
      " [0.5167266 ]\n",
      " [0.5251721 ]\n",
      " [0.58517   ]\n",
      " [0.5038504 ]\n",
      " [0.4693783 ]\n",
      " [0.45318636]\n",
      " [0.4873913 ]\n",
      " [0.5106098 ]\n",
      " [0.54884386]\n",
      " [0.55100906]\n",
      " [0.4964905 ]\n",
      " [0.50627106]\n",
      " [0.4793999 ]\n",
      " [0.5489132 ]\n",
      " [0.5190821 ]\n",
      " [0.5740716 ]\n",
      " [0.45081472]\n",
      " [0.3586993 ]\n",
      " [0.5149778 ]\n",
      " [0.47399187]\n",
      " [0.5245977 ]\n",
      " [0.642103  ]\n",
      " [0.4380769 ]\n",
      " [0.4670933 ]\n",
      " [0.49508986]\n",
      " [0.48756102]\n",
      " [0.5459768 ]\n",
      " [0.40938532]\n",
      " [0.44636425]\n",
      " [0.49854764]\n",
      " [0.5942275 ]\n",
      " [0.41905403]\n",
      " [0.5476081 ]\n",
      " [0.5652497 ]\n",
      " [0.4545451 ]\n",
      " [0.57515883]\n",
      " [0.4361389 ]\n",
      " [0.43601367]\n",
      " [0.49683163]\n",
      " [0.44986063]\n",
      " [0.5618891 ]\n",
      " [0.55232286]\n",
      " [0.5344693 ]\n",
      " [0.41379014]\n",
      " [0.41198012]\n",
      " [0.5264698 ]\n",
      " [0.47416225]\n",
      " [0.4377564 ]\n",
      " [0.46685624]\n",
      " [0.46882707]\n",
      " [0.45909342]\n",
      " [0.54101527]\n",
      " [0.43868384]\n",
      " [0.5430514 ]\n",
      " [0.51314527]\n",
      " [0.60594356]\n",
      " [0.49667025]\n",
      " [0.55124605]\n",
      " [0.57872015]\n",
      " [0.48655018]\n",
      " [0.52082795]\n",
      " [0.51839405]\n",
      " [0.45087352]\n",
      " [0.4116533 ]\n",
      " [0.47761983]\n",
      " [0.39859283]\n",
      " [0.36194167]\n",
      " [0.5678569 ]\n",
      " [0.5834533 ]\n",
      " [0.5867443 ]\n",
      " [0.5157492 ]\n",
      " [0.5168531 ]\n",
      " [0.49689358]\n",
      " [0.54456484]\n",
      " [0.5537644 ]\n",
      " [0.53156006]\n",
      " [0.3537773 ]\n",
      " [0.4414161 ]\n",
      " [0.43568093]\n",
      " [0.4607029 ]\n",
      " [0.6364602 ]\n",
      " [0.49682304]\n",
      " [0.46423024]\n",
      " [0.50982034]\n",
      " [0.47484845]\n",
      " [0.5771485 ]\n",
      " [0.5168007 ]\n",
      " [0.5293977 ]\n",
      " [0.5452691 ]\n",
      " [0.56619114]\n",
      " [0.5869367 ]\n",
      " [0.49430567]\n",
      " [0.501548  ]\n",
      " [0.5303549 ]\n",
      " [0.47237507]\n",
      " [0.49584693]\n",
      " [0.57592505]\n",
      " [0.5681657 ]\n",
      " [0.51212424]\n",
      " [0.5126617 ]\n",
      " [0.5211749 ]\n",
      " [0.48294967]\n",
      " [0.5117872 ]\n",
      " [0.45743832]\n",
      " [0.47001684]\n",
      " [0.44665235]\n",
      " [0.538588  ]\n",
      " [0.47988757]\n",
      " [0.40129876]\n",
      " [0.37457365]\n",
      " [0.54375386]\n",
      " [0.5739034 ]\n",
      " [0.5574311 ]\n",
      " [0.57071567]\n",
      " [0.4670717 ]\n",
      " [0.595793  ]\n",
      " [0.48046085]\n",
      " [0.46758032]\n",
      " [0.44360432]\n",
      " [0.5285928 ]\n",
      " [0.5659549 ]\n",
      " [0.5168611 ]\n",
      " [0.5039926 ]\n",
      " [0.4961884 ]\n",
      " [0.5807303 ]\n",
      " [0.6126673 ]\n",
      " [0.552498  ]\n",
      " [0.62053645]\n",
      " [0.4484194 ]\n",
      " [0.39921927]\n",
      " [0.47139615]\n",
      " [0.55505204]\n",
      " [0.5204979 ]\n",
      " [0.47341722]\n",
      " [0.5012386 ]\n",
      " [0.6382041 ]\n",
      " [0.58367074]\n",
      " [0.53049546]\n",
      " [0.47360843]\n",
      " [0.49939936]\n",
      " [0.4969065 ]\n",
      " [0.56336683]\n",
      " [0.4612742 ]\n",
      " [0.51828223]\n",
      " [0.4752891 ]\n",
      " [0.511835  ]\n",
      " [0.5106496 ]\n",
      " [0.45650294]\n",
      " [0.5246973 ]\n",
      " [0.5142196 ]\n",
      " [0.4929606 ]\n",
      " [0.5076916 ]\n",
      " [0.55231845]\n",
      " [0.60805345]\n",
      " [0.51526785]\n",
      " [0.6411249 ]\n",
      " [0.56123954]\n",
      " [0.4449589 ]\n",
      " [0.44587356]\n",
      " [0.4669543 ]\n",
      " [0.5067329 ]\n",
      " [0.4356481 ]\n",
      " [0.4145255 ]\n",
      " [0.41983494]\n",
      " [0.34247413]\n",
      " [0.63063204]\n",
      " [0.5736271 ]\n",
      " [0.5051724 ]\n",
      " [0.45561957]\n",
      " [0.512697  ]\n",
      " [0.52441543]\n",
      " [0.5847824 ]\n",
      " [0.46309993]\n",
      " [0.48031375]\n",
      " [0.5171257 ]\n",
      " [0.47438374]\n",
      " [0.4509171 ]\n",
      " [0.5180221 ]\n",
      " [0.4886695 ]\n",
      " [0.4428972 ]\n",
      " [0.44541278]\n",
      " [0.40670994]\n",
      " [0.5452756 ]\n",
      " [0.46582484]\n",
      " [0.4822314 ]\n",
      " [0.5382164 ]\n",
      " [0.54482424]\n",
      " [0.40177214]\n",
      " [0.3907609 ]\n",
      " [0.49592534]\n",
      " [0.51210415]\n",
      " [0.4756422 ]\n",
      " [0.6435751 ]\n",
      " [0.53259283]\n",
      " [0.54337096]\n",
      " [0.4486575 ]\n",
      " [0.5295556 ]\n",
      " [0.56733084]\n",
      " [0.51562023]\n",
      " [0.55200547]\n",
      " [0.49286085]\n",
      " [0.4728717 ]\n",
      " [0.3831781 ]\n",
      " [0.6063864 ]\n",
      " [0.55996853]\n",
      " [0.3994749 ]\n",
      " [0.40628216]\n",
      " [0.41166976]\n",
      " [0.5218052 ]\n",
      " [0.38640997]\n",
      " [0.4169157 ]\n",
      " [0.55456144]\n",
      " [0.5041282 ]\n",
      " [0.45757887]\n",
      " [0.5094597 ]\n",
      " [0.48555383]\n",
      " [0.43852675]\n",
      " [0.48503837]\n",
      " [0.44365937]\n",
      " [0.5791888 ]\n",
      " [0.4636385 ]\n",
      " [0.40752837]\n",
      " [0.5743654 ]\n",
      " [0.49733227]\n",
      " [0.5161943 ]\n",
      " [0.5176583 ]\n",
      " [0.60188234]\n",
      " [0.5043269 ]\n",
      " [0.5446621 ]\n",
      " [0.46865687]\n",
      " [0.4623289 ]\n",
      " [0.4390508 ]\n",
      " [0.5090606 ]\n",
      " [0.45347327]\n",
      " [0.4801102 ]\n",
      " [0.55110353]\n",
      " [0.4838913 ]\n",
      " [0.5622399 ]\n",
      " [0.5335312 ]\n",
      " [0.5476628 ]\n",
      " [0.46899727]\n",
      " [0.48406303]\n",
      " [0.47543576]\n",
      " [0.59846956]\n",
      " [0.52022517]\n",
      " [0.48890918]\n",
      " [0.4705209 ]\n",
      " [0.510978  ]\n",
      " [0.471596  ]\n",
      " [0.5201434 ]\n",
      " [0.53425694]\n",
      " [0.4594834 ]\n",
      " [0.45437983]\n",
      " [0.48468488]\n",
      " [0.5501828 ]\n",
      " [0.618129  ]\n",
      " [0.4543402 ]\n",
      " [0.5176671 ]\n",
      " [0.5501348 ]\n",
      " [0.55749   ]\n",
      " [0.42611808]\n",
      " [0.40786186]\n",
      " [0.503589  ]\n",
      " [0.52098703]\n",
      " [0.47803998]\n",
      " [0.48256865]\n",
      " [0.45953095]\n",
      " [0.4184075 ]\n",
      " [0.6256303 ]\n",
      " [0.4644686 ]\n",
      " [0.43553102]\n",
      " [0.52034277]\n",
      " [0.48794156]\n",
      " [0.49299315]\n",
      " [0.5521488 ]\n",
      " [0.5314267 ]\n",
      " [0.46107903]\n",
      " [0.41190228]\n",
      " [0.5093948 ]\n",
      " [0.44022575]\n",
      " [0.5346173 ]\n",
      " [0.43379757]\n",
      " [0.45323417]\n",
      " [0.5468273 ]\n",
      " [0.6342383 ]\n",
      " [0.44114614]\n",
      " [0.38659582]\n",
      " [0.50507814]\n",
      " [0.48759714]\n",
      " [0.50424   ]\n",
      " [0.5030244 ]\n",
      " [0.48314214]\n",
      " [0.4835988 ]\n",
      " [0.6065425 ]\n",
      " [0.5415166 ]\n",
      " [0.4242804 ]\n",
      " [0.56927013]\n",
      " [0.3804416 ]\n",
      " [0.5799376 ]\n",
      " [0.5363595 ]\n",
      " [0.5659795 ]\n",
      " [0.49985385]\n",
      " [0.39929667]\n",
      " [0.5054186 ]\n",
      " [0.51434594]\n",
      " [0.5244817 ]\n",
      " [0.44074833]\n",
      " [0.45082653]\n",
      " [0.52080894]\n",
      " [0.5761868 ]\n",
      " [0.58516926]\n",
      " [0.4161797 ]\n",
      " [0.46230078]\n",
      " [0.5089948 ]\n",
      " [0.5157695 ]\n",
      " [0.4053712 ]\n",
      " [0.5503721 ]\n",
      " [0.5756374 ]\n",
      " [0.44618666]\n",
      " [0.48269433]\n",
      " [0.6011254 ]\n",
      " [0.5195581 ]\n",
      " [0.54634917]\n",
      " [0.5630729 ]\n",
      " [0.55413747]\n",
      " [0.6266281 ]\n",
      " [0.54016954]\n",
      " [0.46218187]\n",
      " [0.4724866 ]\n",
      " [0.5665449 ]\n",
      " [0.5640318 ]\n",
      " [0.5413499 ]\n",
      " [0.5089859 ]\n",
      " [0.41670302]\n",
      " [0.5369207 ]\n",
      " [0.5329937 ]\n",
      " [0.48602867]\n",
      " [0.5391059 ]\n",
      " [0.5583733 ]\n",
      " [0.6591401 ]\n",
      " [0.62836826]\n",
      " [0.54374856]\n",
      " [0.6150094 ]\n",
      " [0.5365829 ]\n",
      " [0.48492172]\n",
      " [0.45190373]\n",
      " [0.51663077]\n",
      " [0.50738233]\n",
      " [0.44187182]\n",
      " [0.5526315 ]\n",
      " [0.5216835 ]\n",
      " [0.47169206]\n",
      " [0.5151139 ]\n",
      " [0.55623287]\n",
      " [0.5464969 ]\n",
      " [0.50999045]\n",
      " [0.5340941 ]\n",
      " [0.5161894 ]\n",
      " [0.51134354]\n",
      " [0.45288056]\n",
      " [0.51605743]\n",
      " [0.4488024 ]\n",
      " [0.4150918 ]\n",
      " [0.6262031 ]\n",
      " [0.51111877]\n",
      " [0.5209642 ]\n",
      " [0.49251765]\n",
      " [0.44804466]\n",
      " [0.568482  ]\n",
      " [0.51938015]\n",
      " [0.47992077]\n",
      " [0.45889944]\n",
      " [0.4041474 ]\n",
      " [0.46599796]\n",
      " [0.5240234 ]\n",
      " [0.43052188]\n",
      " [0.560653  ]\n",
      " [0.51947147]\n",
      " [0.5406109 ]\n",
      " [0.49699208]\n",
      " [0.4749622 ]\n",
      " [0.51285964]\n",
      " [0.522406  ]\n",
      " [0.66088796]\n",
      " [0.5301043 ]\n",
      " [0.45701522]\n",
      " [0.4673586 ]\n",
      " [0.5037244 ]\n",
      " [0.49143767]\n",
      " [0.48693547]\n",
      " [0.51324654]\n",
      " [0.6010603 ]\n",
      " [0.46770814]\n",
      " [0.61652595]\n",
      " [0.41636238]\n",
      " [0.42858288]\n",
      " [0.4999299 ]\n",
      " [0.44461405]\n",
      " [0.48781392]\n",
      " [0.6200363 ]\n",
      " [0.5707826 ]\n",
      " [0.49784184]\n",
      " [0.48155427]\n",
      " [0.5362402 ]\n",
      " [0.50426173]\n",
      " [0.50966   ]\n",
      " [0.48539636]\n",
      " [0.4755709 ]\n",
      " [0.51577735]\n",
      " [0.56814206]\n",
      " [0.60035753]\n",
      " [0.51375777]\n",
      " [0.5428671 ]\n",
      " [0.5034694 ]\n",
      " [0.6903074 ]\n",
      " [0.6281222 ]\n",
      " [0.39151344]\n",
      " [0.5022654 ]\n",
      " [0.4834546 ]\n",
      " [0.4371757 ]\n",
      " [0.387835  ]\n",
      " [0.46732584]\n",
      " [0.4998763 ]\n",
      " [0.44606313]\n",
      " [0.48751354]\n",
      " [0.6179299 ]\n",
      " [0.5671607 ]\n",
      " [0.54239327]\n",
      " [0.5403956 ]\n",
      " [0.46425328]\n",
      " [0.4520488 ]\n",
      " [0.45376486]\n",
      " [0.51419884]\n",
      " [0.5484633 ]\n",
      " [0.49432886]\n",
      " [0.48651916]\n",
      " [0.57605594]\n",
      " [0.4628991 ]\n",
      " [0.48261   ]\n",
      " [0.4618323 ]\n",
      " [0.47848532]\n",
      " [0.5271612 ]\n",
      " [0.49706072]\n",
      " [0.51474375]\n",
      " [0.45343247]\n",
      " [0.5676191 ]\n",
      " [0.48171923]\n",
      " [0.555535  ]\n",
      " [0.518296  ]\n",
      " [0.5073357 ]\n",
      " [0.54448324]\n",
      " [0.5777613 ]\n",
      " [0.5806547 ]\n",
      " [0.49734557]\n",
      " [0.49665532]\n",
      " [0.5651341 ]\n",
      " [0.47104153]\n",
      " [0.5025445 ]\n",
      " [0.62018704]\n",
      " [0.55021584]\n",
      " [0.63340354]\n",
      " [0.6254097 ]\n",
      " [0.39393485]\n",
      " [0.4613908 ]\n",
      " [0.70657015]\n",
      " [0.50904936]\n",
      " [0.52195233]\n",
      " [0.39127302]\n",
      " [0.4449612 ]\n",
      " [0.5351612 ]\n",
      " [0.50736797]\n",
      " [0.45214444]\n",
      " [0.51122564]\n",
      " [0.5120449 ]\n",
      " [0.46896774]\n",
      " [0.4904909 ]\n",
      " [0.55519754]\n",
      " [0.6221851 ]\n",
      " [0.55336326]\n",
      " [0.55804724]\n",
      " [0.49175075]\n",
      " [0.4812275 ]\n",
      " [0.5147372 ]\n",
      " [0.447344  ]\n",
      " [0.4811029 ]\n",
      " [0.47165576]\n",
      " [0.56997925]\n",
      " [0.38814425]\n",
      " [0.54596144]\n",
      " [0.36194167]\n",
      " [0.5307553 ]\n",
      " [0.5697544 ]\n",
      " [0.45444134]\n",
      " [0.57836354]\n",
      " [0.57581306]\n",
      " [0.46219945]\n",
      " [0.5143042 ]\n",
      " [0.52527964]\n",
      " [0.46578315]\n",
      " [0.53158396]\n",
      " [0.4954135 ]\n",
      " [0.5832716 ]\n",
      " [0.6006774 ]\n",
      " [0.4262698 ]\n",
      " [0.45598423]\n",
      " [0.5047438 ]\n",
      " [0.5511089 ]\n",
      " [0.4950966 ]\n",
      " [0.53070486]\n",
      " [0.63655436]\n",
      " [0.58623666]\n",
      " [0.49798572]\n",
      " [0.58612126]\n",
      " [0.60724074]\n",
      " [0.410552  ]\n",
      " [0.57392275]\n",
      " [0.5346899 ]\n",
      " [0.56719077]\n",
      " [0.511018  ]\n",
      " [0.49035737]\n",
      " [0.5048414 ]\n",
      " [0.51362646]\n",
      " [0.58262455]\n",
      " [0.40025365]\n",
      " [0.6146446 ]\n",
      " [0.5164205 ]\n",
      " [0.50270796]\n",
      " [0.6177838 ]\n",
      " [0.4027506 ]\n",
      " [0.47829145]\n",
      " [0.5109664 ]\n",
      " [0.4854925 ]\n",
      " [0.47671452]\n",
      " [0.45759544]\n",
      " [0.49961352]\n",
      " [0.55262023]\n",
      " [0.5402396 ]\n",
      " [0.532936  ]\n",
      " [0.53899884]\n",
      " [0.490416  ]\n",
      " [0.49012712]\n",
      " [0.43896094]\n",
      " [0.46559307]\n",
      " [0.43361178]\n",
      " [0.47151405]\n",
      " [0.61745614]\n",
      " [0.5063548 ]\n",
      " [0.5108592 ]\n",
      " [0.42167577]\n",
      " [0.5618315 ]\n",
      " [0.56133485]\n",
      " [0.5215688 ]\n",
      " [0.48777103]\n",
      " [0.4790974 ]\n",
      " [0.34992537]\n",
      " [0.57766753]\n",
      " [0.45430884]\n",
      " [0.5008087 ]\n",
      " [0.5603407 ]\n",
      " [0.46218696]\n",
      " [0.43402672]\n",
      " [0.42548746]\n",
      " [0.5378377 ]\n",
      " [0.48180836]\n",
      " [0.40326124]\n",
      " [0.45488808]\n",
      " [0.46142372]\n",
      " [0.5153961 ]\n",
      " [0.49736014]\n",
      " [0.50256246]\n",
      " [0.45884466]\n",
      " [0.4534834 ]\n",
      " [0.5356141 ]\n",
      " [0.48768628]\n",
      " [0.5019723 ]\n",
      " [0.5093273 ]\n",
      " [0.52406865]\n",
      " [0.5481008 ]\n",
      " [0.44877052]\n",
      " [0.59763   ]\n",
      " [0.47860393]\n",
      " [0.5413009 ]\n",
      " [0.4964972 ]\n",
      " [0.538336  ]\n",
      " [0.46501258]\n",
      " [0.47697824]\n",
      " [0.49217612]\n",
      " [0.55148154]\n",
      " [0.5106634 ]\n",
      " [0.4886401 ]\n",
      " [0.5180963 ]\n",
      " [0.4983583 ]\n",
      " [0.45769095]\n",
      " [0.46148306]\n",
      " [0.5457536 ]\n",
      " [0.5919181 ]\n",
      " [0.5346855 ]\n",
      " [0.5570311 ]\n",
      " [0.52994144]\n",
      " [0.56880194]\n",
      " [0.49424374]\n",
      " [0.5793725 ]\n",
      " [0.46372595]\n",
      " [0.40295258]\n",
      " [0.5464068 ]\n",
      " [0.4636242 ]\n",
      " [0.40925664]\n",
      " [0.4429949 ]\n",
      " [0.48194957]\n",
      " [0.43823394]\n",
      " [0.44503012]\n",
      " [0.44503012]\n",
      " [0.45072606]\n",
      " [0.45347345]\n",
      " [0.5007229 ]\n",
      " [0.43107983]\n",
      " [0.49937063]\n",
      " [0.41155985]\n",
      " [0.5390117 ]\n",
      " [0.5682833 ]\n",
      " [0.57882255]\n",
      " [0.5849631 ]\n",
      " [0.5181848 ]\n",
      " [0.52691704]\n",
      " [0.44351575]\n",
      " [0.4230491 ]\n",
      " [0.50618726]\n",
      " [0.5291437 ]\n",
      " [0.5075668 ]\n",
      " [0.49251544]\n",
      " [0.55388314]\n",
      " [0.5540767 ]\n",
      " [0.50577253]\n",
      " [0.35182056]\n",
      " [0.4363953 ]\n",
      " [0.49495193]\n",
      " [0.4398446 ]\n",
      " [0.39087072]\n",
      " [0.5452637 ]\n",
      " [0.56748223]\n",
      " [0.54637545]\n",
      " [0.56808764]\n",
      " [0.52119166]\n",
      " [0.646395  ]\n",
      " [0.52223027]\n",
      " [0.5450226 ]\n",
      " [0.5169831 ]\n",
      " [0.50088483]\n",
      " [0.5325474 ]\n",
      " [0.39200634]\n",
      " [0.45055553]\n",
      " [0.42359877]\n",
      " [0.40030327]\n",
      " [0.5394357 ]\n",
      " [0.49113393]\n",
      " [0.44189557]\n",
      " [0.57132274]\n",
      " [0.4794576 ]\n",
      " [0.4864633 ]\n",
      " [0.45836988]\n",
      " [0.54745656]\n",
      " [0.47592536]\n",
      " [0.47784355]\n",
      " [0.4545752 ]\n",
      " [0.5016063 ]\n",
      " [0.5329246 ]\n",
      " [0.5201297 ]\n",
      " [0.4827527 ]\n",
      " [0.40713367]\n",
      " [0.51394045]\n",
      " [0.5041568 ]\n",
      " [0.49922216]\n",
      " [0.59471095]\n",
      " [0.5240774 ]\n",
      " [0.4680794 ]\n",
      " [0.48512152]\n",
      " [0.5570598 ]\n",
      " [0.51054597]\n",
      " [0.52611846]\n",
      " [0.50870144]\n",
      " [0.583844  ]\n",
      " [0.48035505]\n",
      " [0.5639924 ]\n",
      " [0.5640878 ]\n",
      " [0.5229885 ]\n",
      " [0.54485625]\n",
      " [0.5151325 ]\n",
      " [0.6128186 ]\n",
      " [0.517902  ]\n",
      " [0.44676185]\n",
      " [0.5161307 ]\n",
      " [0.53191566]\n",
      " [0.51646066]\n",
      " [0.47495943]\n",
      " [0.4868216 ]\n",
      " [0.44066334]\n",
      " [0.4995368 ]\n",
      " [0.54669   ]\n",
      " [0.49879697]\n",
      " [0.49890545]\n",
      " [0.42526618]\n",
      " [0.43988526]\n",
      " [0.41692984]\n",
      " [0.45926344]\n",
      " [0.49201357]\n",
      " [0.495622  ]\n",
      " [0.50987756]\n",
      " [0.45997486]\n",
      " [0.47835323]\n",
      " [0.43155572]\n",
      " [0.5180019 ]\n",
      " [0.54663026]\n",
      " [0.53494227]\n",
      " [0.41867125]\n",
      " [0.36388952]\n",
      " [0.5159916 ]\n",
      " [0.618405  ]\n",
      " [0.5092782 ]\n",
      " [0.54928726]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['score']=pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21257</td>\n",
       "      <td>[#matthew, ncould, somebody, shoot, #video, it...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500262</td>\n",
       "      <td>[[0.089441895, 0.4333227, 0.16138215, -0.14375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21258</td>\n",
       "      <td>[which, really, sucks, because, typing, mobile...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.548189</td>\n",
       "      <td>[[0.23424134, 0.25051132, 0.11579197, -0.18509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21259</td>\n",
       "      <td>[#afraid, #quiet, ones, they, ones, who, actua...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>[[0.06307171, 0.042609587, 0.071758054, -0.120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21260</td>\n",
       "      <td>[hes, horrible, person, now, gag, see, people,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.440841</td>\n",
       "      <td>[[0.12389825, 0.647158, 0.07964105, 0.02110767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21261</td>\n",
       "      <td>[what, fear, doing, usually, what, need, do, t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.563223</td>\n",
       "      <td>[[-0.45358893, 0.08992868, 0.26345077, -0.0969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>22247</td>\n",
       "      <td>[vs, atlanta, yr, vs, rockies, dbacks, yr, tha...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.363890</td>\n",
       "      <td>[[-1.0402302, -0.45375535, -0.13067436, -0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>22248</td>\n",
       "      <td>[im, shaking, now]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>[[-0.13404948, 0.59542483, 0.16308185, -0.3877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>22249</td>\n",
       "      <td>[guys, dating, yet, #trans, #nervous, #blowjob...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.618405</td>\n",
       "      <td>[[-0.4921757, -0.14156745, 0.11549412, 0.06342...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>22250</td>\n",
       "      <td>[she, listening, eurythmicsnme, polish, gothic...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.509278</td>\n",
       "      <td>[[-0.24457596, 0.50185347, 0.3598852, -0.57467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>22251</td>\n",
       "      <td>[claimed, things, scare, usnbut, tough, becaus...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.549287</td>\n",
       "      <td>[[-0.030488538, -0.027727623, 0.08749278, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  \\\n",
       "0    21257  [#matthew, ncould, somebody, shoot, #video, it...    fear   \n",
       "1    21258  [which, really, sucks, because, typing, mobile...    fear   \n",
       "2    21259  [#afraid, #quiet, ones, they, ones, who, actua...    fear   \n",
       "3    21260  [hes, horrible, person, now, gag, see, people,...    fear   \n",
       "4    21261  [what, fear, doing, usually, what, need, do, t...    fear   \n",
       "..     ...                                                ...     ...   \n",
       "990  22247  [vs, atlanta, yr, vs, rockies, dbacks, yr, tha...    fear   \n",
       "991  22248                                 [im, shaking, now]    fear   \n",
       "992  22249  [guys, dating, yet, #trans, #nervous, #blowjob...    fear   \n",
       "993  22250  [she, listening, eurythmicsnme, polish, gothic...    fear   \n",
       "994  22251  [claimed, things, scare, usnbut, tough, becaus...    fear   \n",
       "\n",
       "        score                                           features  \n",
       "0    0.500262  [[0.089441895, 0.4333227, 0.16138215, -0.14375...  \n",
       "1    0.548189  [[0.23424134, 0.25051132, 0.11579197, -0.18509...  \n",
       "2    0.521536  [[0.06307171, 0.042609587, 0.071758054, -0.120...  \n",
       "3    0.440841  [[0.12389825, 0.647158, 0.07964105, 0.02110767...  \n",
       "4    0.563223  [[-0.45358893, 0.08992868, 0.26345077, -0.0969...  \n",
       "..        ...                                                ...  \n",
       "990  0.363890  [[-1.0402302, -0.45375535, -0.13067436, -0.273...  \n",
       "991  0.515992  [[-0.13404948, 0.59542483, 0.16308185, -0.3877...  \n",
       "992  0.618405  [[-0.4921757, -0.14156745, 0.11549412, 0.06342...  \n",
       "993  0.509278  [[-0.24457596, 0.50185347, 0.3598852, -0.57467...  \n",
       "994  0.549287  [[-0.030488538, -0.027727623, 0.08749278, -0.0...  \n",
       "\n",
       "[995 rows x 5 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop('features',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21257</td>\n",
       "      <td>[#matthew, ncould, somebody, shoot, #video, it...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21258</td>\n",
       "      <td>[which, really, sucks, because, typing, mobile...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.548189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21259</td>\n",
       "      <td>[#afraid, #quiet, ones, they, ones, who, actua...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.521536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21260</td>\n",
       "      <td>[hes, horrible, person, now, gag, see, people,...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.440841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21261</td>\n",
       "      <td>[what, fear, doing, usually, what, need, do, t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.563223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>22247</td>\n",
       "      <td>[vs, atlanta, yr, vs, rockies, dbacks, yr, tha...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.363890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>22248</td>\n",
       "      <td>[im, shaking, now]</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.515992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>22249</td>\n",
       "      <td>[guys, dating, yet, #trans, #nervous, #blowjob...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.618405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>22250</td>\n",
       "      <td>[she, listening, eurythmicsnme, polish, gothic...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.509278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>22251</td>\n",
       "      <td>[claimed, things, scare, usnbut, tough, becaus...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.549287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  \\\n",
       "0    21257  [#matthew, ncould, somebody, shoot, #video, it...    fear   \n",
       "1    21258  [which, really, sucks, because, typing, mobile...    fear   \n",
       "2    21259  [#afraid, #quiet, ones, they, ones, who, actua...    fear   \n",
       "3    21260  [hes, horrible, person, now, gag, see, people,...    fear   \n",
       "4    21261  [what, fear, doing, usually, what, need, do, t...    fear   \n",
       "..     ...                                                ...     ...   \n",
       "990  22247  [vs, atlanta, yr, vs, rockies, dbacks, yr, tha...    fear   \n",
       "991  22248                                 [im, shaking, now]    fear   \n",
       "992  22249  [guys, dating, yet, #trans, #nervous, #blowjob...    fear   \n",
       "993  22250  [she, listening, eurythmicsnme, polish, gothic...    fear   \n",
       "994  22251  [claimed, things, scare, usnbut, tough, becaus...    fear   \n",
       "\n",
       "        score  \n",
       "0    0.500262  \n",
       "1    0.548189  \n",
       "2    0.521536  \n",
       "3    0.440841  \n",
       "4    0.563223  \n",
       "..        ...  \n",
       "990  0.363890  \n",
       "991  0.515992  \n",
       "992  0.618405  \n",
       "993  0.509278  \n",
       "994  0.549287  \n",
       "\n",
       "[995 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
