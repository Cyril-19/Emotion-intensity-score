{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv(\"Desktop/emoint tweet/anger-ratings-0to1.train.txt\", delimiter='\\t', header=None)\n",
    "df1.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                              tweet emotion  score\n",
      "0    10000  How the fu*k! Who the heck! moved my fridge!.....   anger  0.938\n",
      "1    10001  So my Indian Uber driver just called someone t...   anger  0.896\n",
      "2    10002  @DPD_UK I asked for my parcel to be delivered ...   anger  0.896\n",
      "3    10003  so ef whichever butt wipe pulled the fire alar...   anger  0.896\n",
      "4    10004  Don't join @BTCare they put the phone down on ...   anger  0.896\n",
      "..     ...                                                ...     ...    ...\n",
      "852  10852   rose incense are the best thing I've ever bought   anger  0.125\n",
      "853  10853         @jaaames1993 Literally burst out laughing.   anger  0.067\n",
      "854  10854           Follow up. Follow through. Be . #success   anger  0.125\n",
      "855  10855  Wrinkles should merely hide where frown have b...   anger  0.125\n",
      "856  10856  Love the new song I can't stop thinking about ...   anger  0.083\n",
      "\n",
      "[857 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "df1['tweet'] = df1['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(remove_mentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s#@]', '', text)  \n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>how the fuk who the heck moved my fridge shoul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>so my indian uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>i asked for my parcel to be delivered to a pic...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>dont join they put the phone down on you talk ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>10852</td>\n",
       "      <td>rose incense are the best thing ive ever bought</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>10853</td>\n",
       "      <td>literally burst out laughing</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>10854</td>\n",
       "      <td>follow up follow through be #success</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10855</td>\n",
       "      <td>wrinkles should merely hide where frown have b...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>10856</td>\n",
       "      <td>love the new song i cant stop thinking about y...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    10000  how the fuk who the heck moved my fridge shoul...   anger  0.938\n",
       "1    10001  so my indian uber driver just called someone t...   anger  0.896\n",
       "2    10002  i asked for my parcel to be delivered to a pic...   anger  0.896\n",
       "3    10003  so ef whichever butt wipe pulled the fire alar...   anger  0.896\n",
       "4    10004  dont join they put the phone down on you talk ...   anger  0.896\n",
       "..     ...                                                ...     ...    ...\n",
       "852  10852    rose incense are the best thing ive ever bought   anger  0.125\n",
       "853  10853                       literally burst out laughing   anger  0.067\n",
       "854  10854               follow up follow through be #success   anger  0.125\n",
       "855  10855  wrinkles should merely hide where frown have b...   anger  0.125\n",
       "856  10856  love the new song i cant stop thinking about y...   anger  0.083\n",
       "\n",
       "[857 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji(tweet):\n",
    "    text = emoji.demojize(tweet)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tweet'] = df1['tweet'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>[how, the, fuk, who, the, heck, moved, my, fri...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>[so, my, indian, uber, driver, just, called, s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>[i, asked, for, my, parcel, to, be, delivered,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>[so, ef, whichever, butt, wipe, pulled, the, f...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>[dont, join, they, put, the, phone, down, on, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>10852</td>\n",
       "      <td>[rose, incense, are, the, best, thing, ive, ev...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>10853</td>\n",
       "      <td>[literally, burst, out, laughing]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>10854</td>\n",
       "      <td>[follow, up, follow, through, be, #success]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10855</td>\n",
       "      <td>[wrinkles, should, merely, hide, where, frown,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>10856</td>\n",
       "      <td>[love, the, new, song, i, cant, stop, thinking...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    10000  [how, the, fuk, who, the, heck, moved, my, fri...   anger  0.938\n",
       "1    10001  [so, my, indian, uber, driver, just, called, s...   anger  0.896\n",
       "2    10002  [i, asked, for, my, parcel, to, be, delivered,...   anger  0.896\n",
       "3    10003  [so, ef, whichever, butt, wipe, pulled, the, f...   anger  0.896\n",
       "4    10004  [dont, join, they, put, the, phone, down, on, ...   anger  0.896\n",
       "..     ...                                                ...     ...    ...\n",
       "852  10852  [rose, incense, are, the, best, thing, ive, ev...   anger  0.125\n",
       "853  10853                  [literally, burst, out, laughing]   anger  0.067\n",
       "854  10854        [follow, up, follow, through, be, #success]   anger  0.125\n",
       "855  10855  [wrinkles, should, merely, hide, where, frown,...   anger  0.125\n",
       "856  10856  [love, the, new, song, i, cant, stop, thinking...   anger  0.083\n",
       "\n",
       "[857 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
    "    'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your', 'so', 'this', 'all',\n",
    "    'am', 'or', 'but', 'if', 'my', 'me', 'we', 'us', 'our', 'we', 'up', 'down', 'out', 'just', 'how', 'why',\n",
    "    'when', 'where', 'here', 'there', 'about', 'more', 'most', 'some', 'any', 'few', 'many', 'much', 'not',\n",
    "    'only', 'other', 'same', 'such', 'no', 'nor', 'too', 'very', 'can', 'cannot', 'could', 'should', 'would',\n",
    "    'might', 'must', 'shall', 'will', 'isn', 'hasn', 'doesn', 'haven', 'didn', 'hadn', 'wasn', 'weren',\n",
    "    'wouldn', 'shouldn', 'ain', 'aren', 'ma'\n",
    "]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>[fuk, who, heck, moved, fridge, knock, landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>[indian, uber, driver, called, someone, word, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>[asked, parcel, delivered, pick, store, addres...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>[ef, whichever, butt, wipe, pulled, fire, alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>[dont, join, they, put, phone, talk, over, rud...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>10852</td>\n",
       "      <td>[rose, incense, best, thing, ive, ever, bought]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>10853</td>\n",
       "      <td>[literally, burst, laughing]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>10854</td>\n",
       "      <td>[follow, follow, through, #success]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10855</td>\n",
       "      <td>[wrinkles, merely, hide, frown, have, been, ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>10856</td>\n",
       "      <td>[love, new, song, cant, stop, thinking]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    10000  [fuk, who, heck, moved, fridge, knock, landlor...   anger  0.938\n",
       "1    10001  [indian, uber, driver, called, someone, word, ...   anger  0.896\n",
       "2    10002  [asked, parcel, delivered, pick, store, addres...   anger  0.896\n",
       "3    10003  [ef, whichever, butt, wipe, pulled, fire, alar...   anger  0.896\n",
       "4    10004  [dont, join, they, put, phone, talk, over, rud...   anger  0.896\n",
       "..     ...                                                ...     ...    ...\n",
       "852  10852    [rose, incense, best, thing, ive, ever, bought]   anger  0.125\n",
       "853  10853                       [literally, burst, laughing]   anger  0.067\n",
       "854  10854                [follow, follow, through, #success]   anger  0.125\n",
       "855  10855  [wrinkles, merely, hide, frown, have, been, ma...   anger  0.125\n",
       "856  10856            [love, new, song, cant, stop, thinking]   anger  0.083\n",
       "\n",
       "[857 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "model_name='bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(tweet):\n",
    "    tokenized_text = ' '.join(tweet)\n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    \n",
    "    return features\n",
    "\n",
    "df1['features'] = df1['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>[fuk, who, heck, moved, fridge, knock, landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.048211165, 0.55411077, 0.17288177, -0.387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>[indian, uber, driver, called, someone, word, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.114754006, 0.2242083, 0.09101931, -0.1088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>[asked, parcel, delivered, pick, store, addres...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.3445066, -0.026175018, 0.0032749637, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>[ef, whichever, butt, wipe, pulled, fire, alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.08527253, 0.29024652, 0.19312719, -0.0649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>[dont, join, they, put, phone, talk, over, rud...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.19458191, 0.13260978, 0.12249434, -0.2312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>10852</td>\n",
       "      <td>[rose, incense, best, thing, ive, ever, bought]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[[-0.5573598, 0.37391967, -0.46787184, 0.10334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>10853</td>\n",
       "      <td>[literally, burst, laughing]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.067</td>\n",
       "      <td>[[-0.14927039, 0.18389827, 0.047589768, -0.044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>10854</td>\n",
       "      <td>[follow, follow, through, #success]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[[-0.21155725, 0.059810657, 0.18363638, 0.0126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10855</td>\n",
       "      <td>[wrinkles, merely, hide, frown, have, been, ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[[0.040475816, 0.2076654, 0.0045883185, -0.075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>10856</td>\n",
       "      <td>[love, new, song, cant, stop, thinking]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.083</td>\n",
       "      <td>[[-0.052609857, -0.124588385, -0.080250956, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score  \\\n",
       "0    10000  [fuk, who, heck, moved, fridge, knock, landlor...   anger  0.938   \n",
       "1    10001  [indian, uber, driver, called, someone, word, ...   anger  0.896   \n",
       "2    10002  [asked, parcel, delivered, pick, store, addres...   anger  0.896   \n",
       "3    10003  [ef, whichever, butt, wipe, pulled, fire, alar...   anger  0.896   \n",
       "4    10004  [dont, join, they, put, phone, talk, over, rud...   anger  0.896   \n",
       "..     ...                                                ...     ...    ...   \n",
       "852  10852    [rose, incense, best, thing, ive, ever, bought]   anger  0.125   \n",
       "853  10853                       [literally, burst, laughing]   anger  0.067   \n",
       "854  10854                [follow, follow, through, #success]   anger  0.125   \n",
       "855  10855  [wrinkles, merely, hide, frown, have, been, ma...   anger  0.125   \n",
       "856  10856            [love, new, song, cant, stop, thinking]   anger  0.083   \n",
       "\n",
       "                                              features  \n",
       "0    [[-0.048211165, 0.55411077, 0.17288177, -0.387...  \n",
       "1    [[-0.114754006, 0.2242083, 0.09101931, -0.1088...  \n",
       "2    [[-0.3445066, -0.026175018, 0.0032749637, -0.1...  \n",
       "3    [[-0.08527253, 0.29024652, 0.19312719, -0.0649...  \n",
       "4    [[-0.19458191, 0.13260978, 0.12249434, -0.2312...  \n",
       "..                                                 ...  \n",
       "852  [[-0.5573598, 0.37391967, -0.46787184, 0.10334...  \n",
       "853  [[-0.14927039, 0.18389827, 0.047589768, -0.044...  \n",
       "854  [[-0.21155725, 0.059810657, 0.18363638, 0.0126...  \n",
       "855  [[0.040475816, 0.2076654, 0.0045883185, -0.075...  \n",
       "856  [[-0.052609857, -0.124588385, -0.080250956, 0....  \n",
       "\n",
       "[857 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>[fuk, who, heck, moved, fridge, knock, landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.048211165, 0.55411077, 0.17288177, -0.387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>[indian, uber, driver, called, someone, word, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.114754006, 0.2242083, 0.09101931, -0.1088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>[asked, parcel, delivered, pick, store, addres...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.3445066, -0.026175018, 0.0032749637, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>[ef, whichever, butt, wipe, pulled, fire, alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.08527253, 0.29024652, 0.19312719, -0.0649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>[dont, join, they, put, phone, talk, over, rud...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.19458191, 0.13260978, 0.12249434, -0.2312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005</td>\n",
       "      <td>[blood, boiling]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[-0.33847663, 0.43582797, -0.3691528, -0.0296...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>[youve, still, got, whole, season, wentworth, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[-0.2145357, 0.041926354, 0.31682923, -0.3384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>[does, tracking, show, equipment, delivered, w...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[-0.17867346, 0.54314536, 0.12850264, -0.2737...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008</td>\n",
       "      <td>[legit, furious, him, people, fucking, idiots]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[0.12987164, 0.45778227, 0.020973768, -0.0331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>[suppose, work, do, wtf, dude, thanks, pissing...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[0.11742496, 0.36254063, 0.1227451, -0.129079...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                              tweet emotion  score  \\\n",
       "0  10000  [fuk, who, heck, moved, fridge, knock, landlor...   anger  0.938   \n",
       "1  10001  [indian, uber, driver, called, someone, word, ...   anger  0.896   \n",
       "2  10002  [asked, parcel, delivered, pick, store, addres...   anger  0.896   \n",
       "3  10003  [ef, whichever, butt, wipe, pulled, fire, alar...   anger  0.896   \n",
       "4  10004  [dont, join, they, put, phone, talk, over, rud...   anger  0.896   \n",
       "5  10005                                   [blood, boiling]   anger  0.875   \n",
       "6  10006  [youve, still, got, whole, season, wentworth, ...   anger  0.875   \n",
       "7  10007  [does, tracking, show, equipment, delivered, w...   anger  0.875   \n",
       "8  10008     [legit, furious, him, people, fucking, idiots]   anger  0.875   \n",
       "9  10009  [suppose, work, do, wtf, dude, thanks, pissing...   anger  0.875   \n",
       "\n",
       "                                            features  \n",
       "0  [[-0.048211165, 0.55411077, 0.17288177, -0.387...  \n",
       "1  [[-0.114754006, 0.2242083, 0.09101931, -0.1088...  \n",
       "2  [[-0.3445066, -0.026175018, 0.0032749637, -0.1...  \n",
       "3  [[-0.08527253, 0.29024652, 0.19312719, -0.0649...  \n",
       "4  [[-0.19458191, 0.13260978, 0.12249434, -0.2312...  \n",
       "5  [[-0.33847663, 0.43582797, -0.3691528, -0.0296...  \n",
       "6  [[-0.2145357, 0.041926354, 0.31682923, -0.3384...  \n",
       "7  [[-0.17867346, 0.54314536, 0.12850264, -0.2737...  \n",
       "8  [[0.12987164, 0.45778227, 0.020973768, -0.0331...  \n",
       "9  [[0.11742496, 0.36254063, 0.1227451, -0.129079...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "features = df1['features'].tolist()\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "padded_df = df1.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (857, 40, 768)\n"
     ]
    }
   ],
   "source": [
    "X = np.stack(padded_df['features'])\n",
    "print('Input feature shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (857, 40, 768)\n",
      "Output shape: (857,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(padded_df['score']) \n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (857, 40 * 768)) \n",
    "y = np.reshape(y, (857,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 30720)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df1['score'].copy()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 30720)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = len(max(X, key=len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8096)              248717216 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4048)              32776656  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2024)              8195176   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1012)              2049300   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1012)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 506)               512578    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 506)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               64896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 292,319,983\n",
      "Trainable params: 292,319,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8096, input_shape=(30720,), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(4048, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2024, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1012, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(506, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='mean_squared_error', patience=1, mode='min')\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 30720)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tweet'] = df1['tweet'].apply(lambda tokens: ' '.join(tokens))\n",
    "array = df1['tweet'].values\n",
    "tensor = tf.convert_to_tensor(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 30720)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 137s 4s/step - loss: 55.2204 - mean_squared_error: 1.2691\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 120s 4s/step - loss: 20.0903 - mean_squared_error: 0.0463\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 123s 4s/step - loss: 12.6189 - mean_squared_error: 0.0285\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 127s 4s/step - loss: 9.0873 - mean_squared_error: 0.0252\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 128s 4s/step - loss: 6.9675 - mean_squared_error: 0.0252\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 125s 4s/step - loss: 5.5417 - mean_squared_error: 0.0214\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 129s 4s/step - loss: 4.5301 - mean_squared_error: 0.0223\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=27, epochs=10, shuffle=True, verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emointjoy.h5','/Home')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('emointjoy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold= pd.read_csv(\"Desktop/emoint tweet/anger-ratings-0to1.dev.gold.txt\", delimiter='\\t', header=None)\n",
    "gold.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10936</td>\n",
       "      <td>@Jen_ny69 People will always get offended ever...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10937</td>\n",
       "      <td>@gayla_weeks1 I try not to let my anger seep i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10938</td>\n",
       "      <td>I hope my hustle don't offend nobody</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10939</td>\n",
       "      <td>Just watched Django Unchained, Other people ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10940</td>\n",
       "      <td>Lol little things like that make me so angry x</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              tweet emotion  score\n",
       "0   10857  @ZubairSabirPTI  pls dont insult the word 'Molna'   anger  0.479\n",
       "1   10858  @ArcticFantasy I would have almost took offens...   anger  0.458\n",
       "2   10859  @IllinoisLoyalty that Rutgers game was an abom...   anger  0.562\n",
       "3   10860  @CozanGaming that's what lisa asked before she...   anger  0.500\n",
       "4   10861  Sometimes I get mad over something so minuscul...   anger  0.708\n",
       "..    ...                                                ...     ...    ...\n",
       "79  10936  @Jen_ny69 People will always get offended ever...   anger  0.562\n",
       "80  10937  @gayla_weeks1 I try not to let my anger seep i...   anger  0.625\n",
       "81  10938               I hope my hustle don't offend nobody   anger  0.292\n",
       "82  10939  Just watched Django Unchained, Other people ma...   anger  0.229\n",
       "83  10940     Lol little things like that make me so angry x   anger  0.604\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "gold['tweet'] = gold['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>@zubairsabirpti  pls dont insult the word 'molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>@arcticfantasy i would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>@illinoisloyalty that rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>@cozangaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>sometimes i get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10936</td>\n",
       "      <td>@jen_ny69 people will always get offended ever...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10937</td>\n",
       "      <td>@gayla_weeks1 i try not to let my anger seep i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10938</td>\n",
       "      <td>i hope my hustle don't offend nobody</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10939</td>\n",
       "      <td>just watched django unchained, other people ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10940</td>\n",
       "      <td>lol little things like that make me so angry x</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              tweet emotion  score\n",
       "0   10857  @zubairsabirpti  pls dont insult the word 'molna'   anger  0.479\n",
       "1   10858  @arcticfantasy i would have almost took offens...   anger  0.458\n",
       "2   10859  @illinoisloyalty that rutgers game was an abom...   anger  0.562\n",
       "3   10860  @cozangaming that's what lisa asked before she...   anger  0.500\n",
       "4   10861  sometimes i get mad over something so minuscul...   anger  0.708\n",
       "..    ...                                                ...     ...    ...\n",
       "79  10936  @jen_ny69 people will always get offended ever...   anger  0.562\n",
       "80  10937  @gayla_weeks1 i try not to let my anger seep i...   anger  0.625\n",
       "81  10938               i hope my hustle don't offend nobody   anger  0.292\n",
       "82  10939  just watched django unchained, other people ma...   anger  0.229\n",
       "83  10940     lol little things like that make me so angry x   anger  0.604\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>pls dont insult the word 'molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>i would have almost took offense to this if i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>that rutgers game was an abomination. an affr...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>that's what lisa asked before she started rag...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>sometimes i get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10936</td>\n",
       "      <td>people will always get offended everyone's si...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10937</td>\n",
       "      <td>i try not to let my anger seep into reviews, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10938</td>\n",
       "      <td>i hope my hustle don't offend nobody</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10939</td>\n",
       "      <td>just watched django unchained, other people ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10940</td>\n",
       "      <td>lol little things like that make me so angry x</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              tweet emotion  score\n",
       "0   10857                   pls dont insult the word 'molna'   anger  0.479\n",
       "1   10858   i would have almost took offense to this if i...   anger  0.458\n",
       "2   10859   that rutgers game was an abomination. an affr...   anger  0.562\n",
       "3   10860   that's what lisa asked before she started rag...   anger  0.500\n",
       "4   10861  sometimes i get mad over something so minuscul...   anger  0.708\n",
       "..    ...                                                ...     ...    ...\n",
       "79  10936   people will always get offended everyone's si...   anger  0.562\n",
       "80  10937   i try not to let my anger seep into reviews, ...   anger  0.625\n",
       "81  10938               i hope my hustle don't offend nobody   anger  0.292\n",
       "82  10939  just watched django unchained, other people ma...   anger  0.229\n",
       "83  10940     lol little things like that make me so angry x   anger  0.604\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(remove_mentions)\n",
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gold(gold):\n",
    "    gold  = re.sub(r'[^\\w\\s#@]', '', gold ) \n",
    "    gold  = re.sub(r'\\d+', '', gold)  \n",
    "    gold  = re.sub(r'\\s+', ' ', gold).strip()\n",
    "    return gold\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(clean_gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>pls dont insult the word molna</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>i would have almost took offense to this if i ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>that rutgers game was an abomination an affron...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>thats what lisa asked before she started ragin...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>sometimes i get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10936</td>\n",
       "      <td>people will always get offended everyones situ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10937</td>\n",
       "      <td>i try not to let my anger seep into reviews bu...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10938</td>\n",
       "      <td>i hope my hustle dont offend nobody</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10939</td>\n",
       "      <td>just watched django unchained other people may...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10940</td>\n",
       "      <td>lol little things like that make me so angry x</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              tweet emotion  score\n",
       "0   10857                     pls dont insult the word molna   anger  0.479\n",
       "1   10858  i would have almost took offense to this if i ...   anger  0.458\n",
       "2   10859  that rutgers game was an abomination an affron...   anger  0.562\n",
       "3   10860  thats what lisa asked before she started ragin...   anger  0.500\n",
       "4   10861  sometimes i get mad over something so minuscul...   anger  0.708\n",
       "..    ...                                                ...     ...    ...\n",
       "79  10936  people will always get offended everyones situ...   anger  0.562\n",
       "80  10937  i try not to let my anger seep into reviews bu...   anger  0.625\n",
       "81  10938                i hope my hustle dont offend nobody   anger  0.292\n",
       "82  10939  just watched django unchained other people may...   anger  0.229\n",
       "83  10940     lol little things like that make me so angry x   anger  0.604\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji(tweet):\n",
    "    gold = emoji.demojize(tweet)\n",
    "    return gold\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>[pls, dont, insult, the, word, molna]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>[i, would, have, almost, took, offense, to, th...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>[that, rutgers, game, was, an, abomination, an...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>[thats, what, lisa, asked, before, she, starte...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>[sometimes, i, get, mad, over, something, so, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10936</td>\n",
       "      <td>[people, will, always, get, offended, everyone...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10937</td>\n",
       "      <td>[i, try, not, to, let, my, anger, seep, into, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10938</td>\n",
       "      <td>[i, hope, my, hustle, dont, offend, nobody]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10939</td>\n",
       "      <td>[just, watched, django, unchained, other, peop...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10940</td>\n",
       "      <td>[lol, little, things, like, that, make, me, so...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              tweet emotion  score\n",
       "0   10857              [pls, dont, insult, the, word, molna]   anger  0.479\n",
       "1   10858  [i, would, have, almost, took, offense, to, th...   anger  0.458\n",
       "2   10859  [that, rutgers, game, was, an, abomination, an...   anger  0.562\n",
       "3   10860  [thats, what, lisa, asked, before, she, starte...   anger  0.500\n",
       "4   10861  [sometimes, i, get, mad, over, something, so, ...   anger  0.708\n",
       "..    ...                                                ...     ...    ...\n",
       "79  10936  [people, will, always, get, offended, everyone...   anger  0.562\n",
       "80  10937  [i, try, not, to, let, my, anger, seep, into, ...   anger  0.625\n",
       "81  10938        [i, hope, my, hustle, dont, offend, nobody]   anger  0.292\n",
       "82  10939  [just, watched, django, unchained, other, peop...   anger  0.229\n",
       "83  10940  [lol, little, things, like, that, make, me, so...   anger  0.604\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
    "    'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your', 'so', 'this', 'all',\n",
    "    'am', 'or', 'but', 'if', 'my', 'me', 'we', 'us', 'our', 'we', 'up', 'down', 'out', 'just', 'how', 'why',\n",
    "    'when', 'where', 'here', 'there', 'about', 'more', 'most', 'some', 'any', 'few', 'many', 'much', 'not',\n",
    "    'only', 'other', 'same', 'such', 'no', 'nor', 'too', 'very', 'can', 'cannot', 'could', 'should', 'would',\n",
    "    'might', 'must', 'shall', 'will', 'isn', 'hasn', 'doesn', 'haven', 'didn', 'hadn', 'wasn', 'weren',\n",
    "    'wouldn', 'shouldn', 'ain', 'aren', 'ma'\n",
    "]\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "gold['tweet'] = gold['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>[pls, dont, insult, word, molna]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>[have, almost, took, offense, actually, snapped]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>[rutgers, game, abomination, affront, god, man...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>[thats, what, lisa, asked, before, she, starte...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>[sometimes, get, mad, over, something, minuscu...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10936</td>\n",
       "      <td>[people, always, get, offended, everyones, sit...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10937</td>\n",
       "      <td>[try, let, anger, seep, into, reviews, resent,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10938</td>\n",
       "      <td>[hope, hustle, dont, offend, nobody]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10939</td>\n",
       "      <td>[watched, django, unchained, people, may, frow...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10940</td>\n",
       "      <td>[lol, little, things, like, make, angry]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              tweet emotion  score\n",
       "0   10857                   [pls, dont, insult, word, molna]   anger  0.479\n",
       "1   10858   [have, almost, took, offense, actually, snapped]   anger  0.458\n",
       "2   10859  [rutgers, game, abomination, affront, god, man...   anger  0.562\n",
       "3   10860  [thats, what, lisa, asked, before, she, starte...   anger  0.500\n",
       "4   10861  [sometimes, get, mad, over, something, minuscu...   anger  0.708\n",
       "..    ...                                                ...     ...    ...\n",
       "79  10936  [people, always, get, offended, everyones, sit...   anger  0.562\n",
       "80  10937  [try, let, anger, seep, into, reviews, resent,...   anger  0.625\n",
       "81  10938               [hope, hustle, dont, offend, nobody]   anger  0.292\n",
       "82  10939  [watched, django, unchained, people, may, frow...   anger  0.229\n",
       "83  10940           [lol, little, things, like, make, angry]   anger  0.604\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(tweet):\n",
    "    tokenized_text = ' '.join(tweet)\n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    return features\n",
    "\n",
    "\n",
    "gold['features'] = gold['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 768)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold[\"features\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "features =gold['features'].tolist()\n",
    "\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "\n",
    "padded_df = gold.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (84, 43, 768)\n"
     ]
    }
   ],
   "source": [
    "X_gold= np.stack(padded_df['features'])\n",
    "print('Input feature shape:', X_gold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_length = 40\n",
    "\n",
    "padded_gold_data = pad_sequences(X_gold, maxlen=max_sequence_length, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(padded_gold_data, (84, 40 * 768))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_features = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 30720)\n"
     ]
    }
   ],
   "source": [
    "print(gold_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 121ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = loaded_model.predict(gold_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42983025]\n",
      " [0.39067608]\n",
      " [0.4761458 ]\n",
      " [0.41589832]\n",
      " [0.45870632]\n",
      " [0.4723348 ]\n",
      " [0.47835708]\n",
      " [0.5010797 ]\n",
      " [0.49646306]\n",
      " [0.45078397]\n",
      " [0.47035313]\n",
      " [0.4992628 ]\n",
      " [0.48040706]\n",
      " [0.5068386 ]\n",
      " [0.4588393 ]\n",
      " [0.44625086]\n",
      " [0.47188455]\n",
      " [0.4091395 ]\n",
      " [0.37288994]\n",
      " [0.41724902]\n",
      " [0.42723107]\n",
      " [0.4294554 ]\n",
      " [0.3768196 ]\n",
      " [0.44328767]\n",
      " [0.42854536]\n",
      " [0.48328167]\n",
      " [0.43076688]\n",
      " [0.40173358]\n",
      " [0.45567417]\n",
      " [0.4664476 ]\n",
      " [0.3817675 ]\n",
      " [0.39712238]\n",
      " [0.41243452]\n",
      " [0.3542381 ]\n",
      " [0.43463552]\n",
      " [0.4955246 ]\n",
      " [0.45220208]\n",
      " [0.42163926]\n",
      " [0.40661412]\n",
      " [0.39225864]\n",
      " [0.39914083]\n",
      " [0.4055798 ]\n",
      " [0.4092601 ]\n",
      " [0.4164049 ]\n",
      " [0.457775  ]\n",
      " [0.45655042]\n",
      " [0.40969992]\n",
      " [0.40172863]\n",
      " [0.47126442]\n",
      " [0.42962474]\n",
      " [0.42130685]\n",
      " [0.42085493]\n",
      " [0.38543588]\n",
      " [0.48216414]\n",
      " [0.44782507]\n",
      " [0.46181726]\n",
      " [0.37941873]\n",
      " [0.42436415]\n",
      " [0.41671836]\n",
      " [0.48221815]\n",
      " [0.41491187]\n",
      " [0.4152171 ]\n",
      " [0.40396369]\n",
      " [0.40331036]\n",
      " [0.3783309 ]\n",
      " [0.43287504]\n",
      " [0.43131328]\n",
      " [0.38366055]\n",
      " [0.38366055]\n",
      " [0.43132257]\n",
      " [0.3792795 ]\n",
      " [0.3913362 ]\n",
      " [0.41876227]\n",
      " [0.4180056 ]\n",
      " [0.37319607]\n",
      " [0.30444986]\n",
      " [0.44442767]\n",
      " [0.41896302]\n",
      " [0.4435563 ]\n",
      " [0.45634675]\n",
      " [0.4392377 ]\n",
      " [0.39077467]\n",
      " [0.42418593]\n",
      " [0.40567714]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold['prediction']=pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>[pls, dont, insult, word, molna]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[[-0.16410866, 0.59082836, -0.29882964, -0.219...</td>\n",
       "      <td>0.429830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>[have, almost, took, offense, actually, snapped]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[[0.0656415, 0.116881676, 0.07354636, 0.036941...</td>\n",
       "      <td>0.390676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10859</td>\n",
       "      <td>[rutgers, game, abomination, affront, god, man...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[[-0.053360425, 0.269789, 0.00304747, -0.07536...</td>\n",
       "      <td>0.476146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>[thats, what, lisa, asked, before, she, starte...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[[-0.1695536, 0.36146763, 0.1704143, -0.027060...</td>\n",
       "      <td>0.415898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10861</td>\n",
       "      <td>[sometimes, get, mad, over, something, minuscu...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[[0.32172096, -0.21224442, -0.00801837, -0.002...</td>\n",
       "      <td>0.458706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10936</td>\n",
       "      <td>[people, always, get, offended, everyones, sit...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[[0.20103475, 0.36392444, -0.038629428, 0.0799...</td>\n",
       "      <td>0.456347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10937</td>\n",
       "      <td>[try, let, anger, seep, into, reviews, resent,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[[0.15884677, -0.2910138, -0.052284643, 0.0484...</td>\n",
       "      <td>0.439238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10938</td>\n",
       "      <td>[hope, hustle, dont, offend, nobody]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[[-0.023534462, 0.50190735, -0.4802528, -0.017...</td>\n",
       "      <td>0.390775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10939</td>\n",
       "      <td>[watched, django, unchained, people, may, frow...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.229</td>\n",
       "      <td>[[0.15952887, 0.13285294, 0.20451696, 0.080129...</td>\n",
       "      <td>0.424186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10940</td>\n",
       "      <td>[lol, little, things, like, make, angry]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[[-0.13832283, 0.4406555, -0.28989294, 0.06961...</td>\n",
       "      <td>0.405677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              tweet emotion  score  \\\n",
       "0   10857                   [pls, dont, insult, word, molna]   anger  0.479   \n",
       "1   10858   [have, almost, took, offense, actually, snapped]   anger  0.458   \n",
       "2   10859  [rutgers, game, abomination, affront, god, man...   anger  0.562   \n",
       "3   10860  [thats, what, lisa, asked, before, she, starte...   anger  0.500   \n",
       "4   10861  [sometimes, get, mad, over, something, minuscu...   anger  0.708   \n",
       "..    ...                                                ...     ...    ...   \n",
       "79  10936  [people, always, get, offended, everyones, sit...   anger  0.562   \n",
       "80  10937  [try, let, anger, seep, into, reviews, resent,...   anger  0.625   \n",
       "81  10938               [hope, hustle, dont, offend, nobody]   anger  0.292   \n",
       "82  10939  [watched, django, unchained, people, may, frow...   anger  0.229   \n",
       "83  10940           [lol, little, things, like, make, angry]   anger  0.604   \n",
       "\n",
       "                                             features  prediction  \n",
       "0   [[-0.16410866, 0.59082836, -0.29882964, -0.219...    0.429830  \n",
       "1   [[0.0656415, 0.116881676, 0.07354636, 0.036941...    0.390676  \n",
       "2   [[-0.053360425, 0.269789, 0.00304747, -0.07536...    0.476146  \n",
       "3   [[-0.1695536, 0.36146763, 0.1704143, -0.027060...    0.415898  \n",
       "4   [[0.32172096, -0.21224442, -0.00801837, -0.002...    0.458706  \n",
       "..                                                ...         ...  \n",
       "79  [[0.20103475, 0.36392444, -0.038629428, 0.0799...    0.456347  \n",
       "80  [[0.15884677, -0.2910138, -0.052284643, 0.0484...    0.439238  \n",
       "81  [[-0.023534462, 0.50190735, -0.4802528, -0.017...    0.390775  \n",
       "82  [[0.15952887, 0.13285294, 0.20451696, 0.080129...    0.424186  \n",
       "83  [[-0.13832283, 0.4406555, -0.28989294, 0.06961...    0.405677  \n",
       "\n",
       "[84 rows x 6 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square Error: 0.027248999115929234\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(gold['score'], gold['prediction'])\n",
    "print(\"Mean square Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"Desktop/emoint tweet/anger-ratings-0to1.test.target.txt\", delimiter='\\t', header=None)\n",
    "test.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "test['tweet'] = test['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>at the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>it's game day!!!!      t minus 14:30  #relen...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>this game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>i've just found out it's candice and not cand...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>if he can't come to my mum'a 60th after 25...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>what if the supposed animosity is all bullshi...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>will byu's offense score 24+ vs wvu?</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>id love 2 c gyimah in action but his coach is ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>forgiving means operating with god's spirit &amp;a...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>i've got a lot of tokens saved up and i wanna ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion score\n",
       "0    10941  at the point today where if someone says somet...   anger  NONE\n",
       "1    10942    it's game day!!!!      t minus 14:30  #relen...   anger  NONE\n",
       "2    10943  this game has pissed me off more than any othe...   anger  NONE\n",
       "3    10944   i've just found out it's candice and not cand...   anger  NONE\n",
       "4    10945      if he can't come to my mum'a 60th after 25...   anger  NONE\n",
       "..     ...                                                ...     ...   ...\n",
       "755  11696   what if the supposed animosity is all bullshi...   anger  NONE\n",
       "756  11697               will byu's offense score 24+ vs wvu?   anger  NONE\n",
       "757  11698  id love 2 c gyimah in action but his coach is ...   anger  NONE\n",
       "758  11699  forgiving means operating with god's spirit &a...   anger  NONE\n",
       "759  11700  i've got a lot of tokens saved up and i wanna ...   anger  NONE\n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(remove_mentions)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_test(test):\n",
    "    test  = re.sub(r'[^\\w\\s#@]', '', test ) \n",
    "    test  = re.sub(r'\\d+', '', test)  \n",
    "    test  = re.sub(r'\\s+', ' ', test).strip()\n",
    "    return test\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(clean_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
    "    'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your', 'so', 'this', 'all',\n",
    "    'am', 'or', 'but', 'if', 'my', 'me', 'we', 'us', 'our', 'we', 'up', 'down', 'out', 'just', 'how', 'why',\n",
    "    'when', 'where', 'here', 'there', 'about', 'more', 'most', 'some', 'any', 'few', 'many', 'much', 'not',\n",
    "    'only', 'other', 'same', 'such', 'no', 'nor', 'too', 'very', 'can', 'cannot', 'could', 'should', 'would',\n",
    "    'might', 'must', 'shall', 'will', 'isn', 'hasn', 'doesn', 'haven', 'didn', 'hadn', 'wasn', 'weren',\n",
    "    'wouldn', 'shouldn', 'ain', 'aren', 'ma'\n",
    "]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(tweet):\n",
    "    tokenized_text = ' '.join(tweet)\n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    return features\n",
    "\n",
    "\n",
    "test['features'] = test['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 768)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"features\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "features =test['features'].tolist()\n",
    "\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "\n",
    "padded_df = test.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (760, 43, 768)\n"
     ]
    }
   ],
   "source": [
    "X_test= np.stack(padded_df['features'])\n",
    "print('Input feature shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 40, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_length = 40\n",
    "truncated_test_data = pad_sequences(X_test, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "print(truncated_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(truncated_test_data, (760, 40 * 768)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 30720)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 4s 145ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = loaded_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45113027]\n",
      " [0.37854362]\n",
      " [0.51050544]\n",
      " [0.37354475]\n",
      " [0.4745111 ]\n",
      " [0.4684605 ]\n",
      " [0.3836341 ]\n",
      " [0.52161586]\n",
      " [0.43736106]\n",
      " [0.35865605]\n",
      " [0.4083417 ]\n",
      " [0.4222024 ]\n",
      " [0.45327616]\n",
      " [0.50875306]\n",
      " [0.46213943]\n",
      " [0.33236104]\n",
      " [0.36837047]\n",
      " [0.41316688]\n",
      " [0.42072517]\n",
      " [0.44420278]\n",
      " [0.46509486]\n",
      " [0.44261724]\n",
      " [0.49337047]\n",
      " [0.47385502]\n",
      " [0.42259175]\n",
      " [0.39641058]\n",
      " [0.40106475]\n",
      " [0.48621994]\n",
      " [0.44472313]\n",
      " [0.437231  ]\n",
      " [0.36148798]\n",
      " [0.4926566 ]\n",
      " [0.49737036]\n",
      " [0.5074878 ]\n",
      " [0.44984353]\n",
      " [0.40119946]\n",
      " [0.44292665]\n",
      " [0.4810394 ]\n",
      " [0.35033333]\n",
      " [0.536826  ]\n",
      " [0.5349749 ]\n",
      " [0.45201528]\n",
      " [0.49917078]\n",
      " [0.50610703]\n",
      " [0.44630247]\n",
      " [0.46070343]\n",
      " [0.45595294]\n",
      " [0.46042192]\n",
      " [0.423343  ]\n",
      " [0.40308785]\n",
      " [0.4361472 ]\n",
      " [0.4090435 ]\n",
      " [0.42636746]\n",
      " [0.47573394]\n",
      " [0.44350028]\n",
      " [0.29299647]\n",
      " [0.29796726]\n",
      " [0.5008431 ]\n",
      " [0.48456275]\n",
      " [0.41731203]\n",
      " [0.40754902]\n",
      " [0.42641103]\n",
      " [0.37447172]\n",
      " [0.48588938]\n",
      " [0.45226282]\n",
      " [0.45597625]\n",
      " [0.4142797 ]\n",
      " [0.38528705]\n",
      " [0.43058962]\n",
      " [0.42641282]\n",
      " [0.44534016]\n",
      " [0.40480375]\n",
      " [0.3902805 ]\n",
      " [0.40176135]\n",
      " [0.50538754]\n",
      " [0.44565642]\n",
      " [0.45992458]\n",
      " [0.47335613]\n",
      " [0.39102787]\n",
      " [0.38999563]\n",
      " [0.4680376 ]\n",
      " [0.46171975]\n",
      " [0.37845343]\n",
      " [0.40957087]\n",
      " [0.41657084]\n",
      " [0.41716164]\n",
      " [0.4265458 ]\n",
      " [0.4501384 ]\n",
      " [0.4135552 ]\n",
      " [0.39253527]\n",
      " [0.41966087]\n",
      " [0.4377414 ]\n",
      " [0.439694  ]\n",
      " [0.40639436]\n",
      " [0.5308287 ]\n",
      " [0.53202945]\n",
      " [0.5251705 ]\n",
      " [0.5249263 ]\n",
      " [0.46327066]\n",
      " [0.45955288]\n",
      " [0.37727672]\n",
      " [0.43504173]\n",
      " [0.45021826]\n",
      " [0.4148212 ]\n",
      " [0.40123767]\n",
      " [0.39434403]\n",
      " [0.39545804]\n",
      " [0.39631242]\n",
      " [0.4186499 ]\n",
      " [0.3764767 ]\n",
      " [0.3877372 ]\n",
      " [0.4561507 ]\n",
      " [0.40413827]\n",
      " [0.38519263]\n",
      " [0.4596569 ]\n",
      " [0.43653345]\n",
      " [0.44118804]\n",
      " [0.42943537]\n",
      " [0.46040273]\n",
      " [0.36437094]\n",
      " [0.35924953]\n",
      " [0.3554833 ]\n",
      " [0.47534525]\n",
      " [0.3953951 ]\n",
      " [0.38306278]\n",
      " [0.4728123 ]\n",
      " [0.40104914]\n",
      " [0.3173874 ]\n",
      " [0.40677297]\n",
      " [0.4176756 ]\n",
      " [0.4819582 ]\n",
      " [0.48218203]\n",
      " [0.48239493]\n",
      " [0.38861483]\n",
      " [0.53497314]\n",
      " [0.5198414 ]\n",
      " [0.52796626]\n",
      " [0.3976758 ]\n",
      " [0.38206202]\n",
      " [0.40128195]\n",
      " [0.39554507]\n",
      " [0.43879414]\n",
      " [0.42114466]\n",
      " [0.39057088]\n",
      " [0.47536653]\n",
      " [0.4655339 ]\n",
      " [0.4531077 ]\n",
      " [0.4201253 ]\n",
      " [0.3035928 ]\n",
      " [0.49768162]\n",
      " [0.44450122]\n",
      " [0.47574854]\n",
      " [0.40156   ]\n",
      " [0.50136685]\n",
      " [0.48399663]\n",
      " [0.42918885]\n",
      " [0.5078863 ]\n",
      " [0.48674303]\n",
      " [0.44305474]\n",
      " [0.40631694]\n",
      " [0.49236715]\n",
      " [0.48220736]\n",
      " [0.38703233]\n",
      " [0.3669781 ]\n",
      " [0.49739635]\n",
      " [0.43641722]\n",
      " [0.42305917]\n",
      " [0.40377456]\n",
      " [0.5040435 ]\n",
      " [0.5138819 ]\n",
      " [0.4617589 ]\n",
      " [0.4099971 ]\n",
      " [0.44478714]\n",
      " [0.3974067 ]\n",
      " [0.4685967 ]\n",
      " [0.3505394 ]\n",
      " [0.35286295]\n",
      " [0.39657485]\n",
      " [0.4160245 ]\n",
      " [0.4602785 ]\n",
      " [0.38273972]\n",
      " [0.35356706]\n",
      " [0.4839539 ]\n",
      " [0.49218112]\n",
      " [0.44423324]\n",
      " [0.4393524 ]\n",
      " [0.41764843]\n",
      " [0.44208437]\n",
      " [0.41270417]\n",
      " [0.37842333]\n",
      " [0.39058572]\n",
      " [0.38744187]\n",
      " [0.43918198]\n",
      " [0.4061076 ]\n",
      " [0.4666742 ]\n",
      " [0.4756264 ]\n",
      " [0.34726524]\n",
      " [0.4727922 ]\n",
      " [0.45437324]\n",
      " [0.45346612]\n",
      " [0.457263  ]\n",
      " [0.41014755]\n",
      " [0.47111237]\n",
      " [0.4521408 ]\n",
      " [0.44336063]\n",
      " [0.48698074]\n",
      " [0.42355168]\n",
      " [0.3923089 ]\n",
      " [0.48743647]\n",
      " [0.3662004 ]\n",
      " [0.38422477]\n",
      " [0.43399608]\n",
      " [0.44287765]\n",
      " [0.38501465]\n",
      " [0.5294722 ]\n",
      " [0.40911365]\n",
      " [0.4625153 ]\n",
      " [0.43553364]\n",
      " [0.39810485]\n",
      " [0.41682428]\n",
      " [0.41009277]\n",
      " [0.33178896]\n",
      " [0.42970508]\n",
      " [0.46430475]\n",
      " [0.45978415]\n",
      " [0.4444309 ]\n",
      " [0.40159017]\n",
      " [0.3383959 ]\n",
      " [0.42462248]\n",
      " [0.41146755]\n",
      " [0.47490257]\n",
      " [0.4031273 ]\n",
      " [0.46857518]\n",
      " [0.4227823 ]\n",
      " [0.42051315]\n",
      " [0.38900572]\n",
      " [0.3929054 ]\n",
      " [0.40095842]\n",
      " [0.33848286]\n",
      " [0.29759502]\n",
      " [0.5043937 ]\n",
      " [0.42115438]\n",
      " [0.45376587]\n",
      " [0.39421284]\n",
      " [0.48513955]\n",
      " [0.4567775 ]\n",
      " [0.4394796 ]\n",
      " [0.40523243]\n",
      " [0.4139505 ]\n",
      " [0.49111152]\n",
      " [0.4414839 ]\n",
      " [0.45293158]\n",
      " [0.44255745]\n",
      " [0.40150148]\n",
      " [0.40592653]\n",
      " [0.44705528]\n",
      " [0.41990185]\n",
      " [0.43452108]\n",
      " [0.39066136]\n",
      " [0.42868936]\n",
      " [0.41435808]\n",
      " [0.42958874]\n",
      " [0.48837596]\n",
      " [0.4706264 ]\n",
      " [0.5049054 ]\n",
      " [0.49513733]\n",
      " [0.46388894]\n",
      " [0.39466792]\n",
      " [0.45202982]\n",
      " [0.4497679 ]\n",
      " [0.40267724]\n",
      " [0.4753241 ]\n",
      " [0.45498753]\n",
      " [0.4305817 ]\n",
      " [0.37730038]\n",
      " [0.39429682]\n",
      " [0.4350931 ]\n",
      " [0.50366956]\n",
      " [0.38975394]\n",
      " [0.44940543]\n",
      " [0.46760243]\n",
      " [0.4451654 ]\n",
      " [0.3753804 ]\n",
      " [0.43106467]\n",
      " [0.33940303]\n",
      " [0.37558532]\n",
      " [0.45364553]\n",
      " [0.41530687]\n",
      " [0.44793922]\n",
      " [0.4152034 ]\n",
      " [0.45801997]\n",
      " [0.35772216]\n",
      " [0.4068849 ]\n",
      " [0.4438485 ]\n",
      " [0.4386409 ]\n",
      " [0.45377457]\n",
      " [0.45743263]\n",
      " [0.46535164]\n",
      " [0.48295236]\n",
      " [0.4142496 ]\n",
      " [0.4908566 ]\n",
      " [0.44573897]\n",
      " [0.4592421 ]\n",
      " [0.3437323 ]\n",
      " [0.4933402 ]\n",
      " [0.50430673]\n",
      " [0.42223394]\n",
      " [0.40819955]\n",
      " [0.37452447]\n",
      " [0.43174654]\n",
      " [0.4150843 ]\n",
      " [0.33158463]\n",
      " [0.42216873]\n",
      " [0.44489062]\n",
      " [0.41727924]\n",
      " [0.42459977]\n",
      " [0.41680187]\n",
      " [0.481889  ]\n",
      " [0.4683392 ]\n",
      " [0.35940236]\n",
      " [0.4202304 ]\n",
      " [0.47579777]\n",
      " [0.42454797]\n",
      " [0.38629186]\n",
      " [0.3966174 ]\n",
      " [0.50599396]\n",
      " [0.4326346 ]\n",
      " [0.42083007]\n",
      " [0.37500817]\n",
      " [0.44727027]\n",
      " [0.42759407]\n",
      " [0.40784168]\n",
      " [0.38961464]\n",
      " [0.45652515]\n",
      " [0.48902476]\n",
      " [0.44540846]\n",
      " [0.42767322]\n",
      " [0.38461554]\n",
      " [0.43730348]\n",
      " [0.40103352]\n",
      " [0.42986667]\n",
      " [0.44596636]\n",
      " [0.46964723]\n",
      " [0.42988735]\n",
      " [0.4360531 ]\n",
      " [0.4680373 ]\n",
      " [0.39523757]\n",
      " [0.3812759 ]\n",
      " [0.4172501 ]\n",
      " [0.48937726]\n",
      " [0.38776088]\n",
      " [0.41445416]\n",
      " [0.389417  ]\n",
      " [0.45343268]\n",
      " [0.4778505 ]\n",
      " [0.45522797]\n",
      " [0.43312842]\n",
      " [0.40720838]\n",
      " [0.41826922]\n",
      " [0.35525566]\n",
      " [0.4834323 ]\n",
      " [0.39313513]\n",
      " [0.42955834]\n",
      " [0.5188946 ]\n",
      " [0.4858426 ]\n",
      " [0.48267674]\n",
      " [0.380073  ]\n",
      " [0.39059603]\n",
      " [0.3879503 ]\n",
      " [0.5180756 ]\n",
      " [0.47851032]\n",
      " [0.44494605]\n",
      " [0.41840816]\n",
      " [0.35912597]\n",
      " [0.44263977]\n",
      " [0.38893038]\n",
      " [0.43299943]\n",
      " [0.38057435]\n",
      " [0.3993709 ]\n",
      " [0.4755633 ]\n",
      " [0.4839192 ]\n",
      " [0.40703297]\n",
      " [0.40228724]\n",
      " [0.43123704]\n",
      " [0.36113423]\n",
      " [0.4631287 ]\n",
      " [0.47311455]\n",
      " [0.37743402]\n",
      " [0.48298305]\n",
      " [0.44560218]\n",
      " [0.41756195]\n",
      " [0.4127121 ]\n",
      " [0.39733827]\n",
      " [0.47215962]\n",
      " [0.50324905]\n",
      " [0.4319753 ]\n",
      " [0.4105404 ]\n",
      " [0.32019055]\n",
      " [0.4115026 ]\n",
      " [0.4453649 ]\n",
      " [0.41666842]\n",
      " [0.39774692]\n",
      " [0.38094002]\n",
      " [0.37300456]\n",
      " [0.3991773 ]\n",
      " [0.47263432]\n",
      " [0.5092052 ]\n",
      " [0.47755265]\n",
      " [0.4012714 ]\n",
      " [0.45891583]\n",
      " [0.5270039 ]\n",
      " [0.43560815]\n",
      " [0.3323965 ]\n",
      " [0.40263778]\n",
      " [0.42297143]\n",
      " [0.43447435]\n",
      " [0.46149158]\n",
      " [0.3584383 ]\n",
      " [0.45407832]\n",
      " [0.4185331 ]\n",
      " [0.40095854]\n",
      " [0.44105226]\n",
      " [0.4599133 ]\n",
      " [0.43843204]\n",
      " [0.49986804]\n",
      " [0.45305645]\n",
      " [0.4307726 ]\n",
      " [0.47502112]\n",
      " [0.45457256]\n",
      " [0.3735972 ]\n",
      " [0.500763  ]\n",
      " [0.42451036]\n",
      " [0.35641664]\n",
      " [0.47371912]\n",
      " [0.46373236]\n",
      " [0.39568907]\n",
      " [0.4562356 ]\n",
      " [0.43449503]\n",
      " [0.4296435 ]\n",
      " [0.4602487 ]\n",
      " [0.50113255]\n",
      " [0.40539896]\n",
      " [0.43573332]\n",
      " [0.4321757 ]\n",
      " [0.34864455]\n",
      " [0.43596447]\n",
      " [0.45634717]\n",
      " [0.38908136]\n",
      " [0.43369812]\n",
      " [0.44477493]\n",
      " [0.48787296]\n",
      " [0.4801935 ]\n",
      " [0.47126496]\n",
      " [0.43618405]\n",
      " [0.4032572 ]\n",
      " [0.34888119]\n",
      " [0.42468405]\n",
      " [0.39563042]\n",
      " [0.46704805]\n",
      " [0.43315893]\n",
      " [0.45063055]\n",
      " [0.43312132]\n",
      " [0.4222579 ]\n",
      " [0.40999156]\n",
      " [0.39146936]\n",
      " [0.428271  ]\n",
      " [0.41330022]\n",
      " [0.3845085 ]\n",
      " [0.46383017]\n",
      " [0.4638757 ]\n",
      " [0.5004305 ]\n",
      " [0.4722739 ]\n",
      " [0.45903325]\n",
      " [0.36081958]\n",
      " [0.4222024 ]\n",
      " [0.43339336]\n",
      " [0.47453606]\n",
      " [0.4108318 ]\n",
      " [0.40308517]\n",
      " [0.4135667 ]\n",
      " [0.46919107]\n",
      " [0.43401074]\n",
      " [0.5227277 ]\n",
      " [0.4275825 ]\n",
      " [0.45062482]\n",
      " [0.45851052]\n",
      " [0.42023176]\n",
      " [0.40015227]\n",
      " [0.4944402 ]\n",
      " [0.44110864]\n",
      " [0.43778688]\n",
      " [0.48431402]\n",
      " [0.45905697]\n",
      " [0.4480545 ]\n",
      " [0.41224074]\n",
      " [0.45356876]\n",
      " [0.46650267]\n",
      " [0.37121868]\n",
      " [0.5025816 ]\n",
      " [0.47977322]\n",
      " [0.41078758]\n",
      " [0.39802557]\n",
      " [0.44530022]\n",
      " [0.33989066]\n",
      " [0.4185331 ]\n",
      " [0.44181746]\n",
      " [0.34589177]\n",
      " [0.40693307]\n",
      " [0.4824245 ]\n",
      " [0.4646517 ]\n",
      " [0.51472026]\n",
      " [0.34975934]\n",
      " [0.44472557]\n",
      " [0.42735076]\n",
      " [0.43399382]\n",
      " [0.35762513]\n",
      " [0.44804335]\n",
      " [0.45796525]\n",
      " [0.4570765 ]\n",
      " [0.44373316]\n",
      " [0.3790043 ]\n",
      " [0.38038188]\n",
      " [0.47210526]\n",
      " [0.40772682]\n",
      " [0.42185944]\n",
      " [0.40993977]\n",
      " [0.40547657]\n",
      " [0.33448708]\n",
      " [0.40750313]\n",
      " [0.40465552]\n",
      " [0.40509653]\n",
      " [0.46130806]\n",
      " [0.4581362 ]\n",
      " [0.4114285 ]\n",
      " [0.3970185 ]\n",
      " [0.41010052]\n",
      " [0.4512986 ]\n",
      " [0.44747674]\n",
      " [0.3946836 ]\n",
      " [0.39349627]\n",
      " [0.45473653]\n",
      " [0.43652946]\n",
      " [0.4226094 ]\n",
      " [0.47433293]\n",
      " [0.4963628 ]\n",
      " [0.3796633 ]\n",
      " [0.4077015 ]\n",
      " [0.37541628]\n",
      " [0.34037942]\n",
      " [0.42907548]\n",
      " [0.3959455 ]\n",
      " [0.3663177 ]\n",
      " [0.442217  ]\n",
      " [0.5599472 ]\n",
      " [0.50791144]\n",
      " [0.45578873]\n",
      " [0.503637  ]\n",
      " [0.5246477 ]\n",
      " [0.49866164]\n",
      " [0.41332358]\n",
      " [0.47774553]\n",
      " [0.5102485 ]\n",
      " [0.46562672]\n",
      " [0.3644554 ]\n",
      " [0.33013046]\n",
      " [0.45516402]\n",
      " [0.46712583]\n",
      " [0.47849196]\n",
      " [0.37968302]\n",
      " [0.4321828 ]\n",
      " [0.5530892 ]\n",
      " [0.54559004]\n",
      " [0.4158355 ]\n",
      " [0.4223256 ]\n",
      " [0.47001815]\n",
      " [0.47175825]\n",
      " [0.4422531 ]\n",
      " [0.5256953 ]\n",
      " [0.4724391 ]\n",
      " [0.45264107]\n",
      " [0.45199054]\n",
      " [0.43106377]\n",
      " [0.43086708]\n",
      " [0.38831824]\n",
      " [0.34580386]\n",
      " [0.39547414]\n",
      " [0.4613672 ]\n",
      " [0.45547545]\n",
      " [0.44743663]\n",
      " [0.3226614 ]\n",
      " [0.4645331 ]\n",
      " [0.41476732]\n",
      " [0.44755638]\n",
      " [0.3661402 ]\n",
      " [0.47872812]\n",
      " [0.46347976]\n",
      " [0.34639102]\n",
      " [0.36445767]\n",
      " [0.40483338]\n",
      " [0.45690966]\n",
      " [0.40158665]\n",
      " [0.4444732 ]\n",
      " [0.4838388 ]\n",
      " [0.3823676 ]\n",
      " [0.5034203 ]\n",
      " [0.4708854 ]\n",
      " [0.48590434]\n",
      " [0.4443887 ]\n",
      " [0.410313  ]\n",
      " [0.37507194]\n",
      " [0.46337342]\n",
      " [0.46136582]\n",
      " [0.43586773]\n",
      " [0.3441589 ]\n",
      " [0.35666168]\n",
      " [0.43181866]\n",
      " [0.4004255 ]\n",
      " [0.45157737]\n",
      " [0.43627053]\n",
      " [0.39497155]\n",
      " [0.39502424]\n",
      " [0.35140318]\n",
      " [0.4609959 ]\n",
      " [0.38953084]\n",
      " [0.42844856]\n",
      " [0.44426185]\n",
      " [0.45572102]\n",
      " [0.442028  ]\n",
      " [0.50454193]\n",
      " [0.4054759 ]\n",
      " [0.4258604 ]\n",
      " [0.47238058]\n",
      " [0.36855882]\n",
      " [0.41130447]\n",
      " [0.41298217]\n",
      " [0.51395327]\n",
      " [0.5434225 ]\n",
      " [0.41172725]\n",
      " [0.43965703]\n",
      " [0.30924946]\n",
      " [0.43352228]\n",
      " [0.44515347]\n",
      " [0.3962553 ]\n",
      " [0.4696421 ]\n",
      " [0.45292318]\n",
      " [0.4339918 ]\n",
      " [0.42090338]\n",
      " [0.4123736 ]\n",
      " [0.42161387]\n",
      " [0.42887014]\n",
      " [0.4982984 ]\n",
      " [0.4787051 ]\n",
      " [0.4760064 ]\n",
      " [0.48681575]\n",
      " [0.43137336]\n",
      " [0.4303879 ]\n",
      " [0.4302988 ]\n",
      " [0.5427765 ]\n",
      " [0.48791003]\n",
      " [0.48762167]\n",
      " [0.43968487]\n",
      " [0.39716196]\n",
      " [0.40858215]\n",
      " [0.47201306]\n",
      " [0.42440462]\n",
      " [0.388151  ]\n",
      " [0.38509727]\n",
      " [0.34960735]\n",
      " [0.42548543]\n",
      " [0.42230988]\n",
      " [0.5456891 ]\n",
      " [0.44461238]\n",
      " [0.40827435]\n",
      " [0.48079652]\n",
      " [0.38829923]\n",
      " [0.3662448 ]\n",
      " [0.42397004]\n",
      " [0.4639287 ]\n",
      " [0.43185312]\n",
      " [0.4243275 ]\n",
      " [0.4422714 ]\n",
      " [0.42671174]\n",
      " [0.43382645]\n",
      " [0.44234282]\n",
      " [0.49330336]\n",
      " [0.43618357]\n",
      " [0.41347927]\n",
      " [0.42465335]\n",
      " [0.41815645]\n",
      " [0.39351755]\n",
      " [0.31738925]\n",
      " [0.47513628]\n",
      " [0.42967796]\n",
      " [0.37416267]\n",
      " [0.4279834 ]\n",
      " [0.3675887 ]\n",
      " [0.36657912]\n",
      " [0.41329175]\n",
      " [0.4300295 ]\n",
      " [0.42776555]\n",
      " [0.39155203]\n",
      " [0.40954345]\n",
      " [0.45072573]\n",
      " [0.4480477 ]\n",
      " [0.3747608 ]\n",
      " [0.4747752 ]\n",
      " [0.35743797]\n",
      " [0.42756695]\n",
      " [0.39971572]\n",
      " [0.42169446]\n",
      " [0.43687707]\n",
      " [0.46086472]\n",
      " [0.52969253]\n",
      " [0.508149  ]\n",
      " [0.45990312]\n",
      " [0.44965023]\n",
      " [0.55322933]\n",
      " [0.4946732 ]\n",
      " [0.49918264]\n",
      " [0.45594466]\n",
      " [0.38915366]\n",
      " [0.43886065]\n",
      " [0.38400847]\n",
      " [0.37852973]\n",
      " [0.45088595]\n",
      " [0.47329324]\n",
      " [0.3406675 ]\n",
      " [0.39272594]\n",
      " [0.5004063 ]\n",
      " [0.47087556]\n",
      " [0.45046932]\n",
      " [0.46283352]\n",
      " [0.4703461 ]\n",
      " [0.48368895]\n",
      " [0.36607438]\n",
      " [0.38598782]\n",
      " [0.3625208 ]\n",
      " [0.38516235]\n",
      " [0.5023075 ]\n",
      " [0.48590904]\n",
      " [0.42889124]\n",
      " [0.41300106]\n",
      " [0.39553988]\n",
      " [0.39968783]\n",
      " [0.47216278]\n",
      " [0.4198298 ]\n",
      " [0.42300594]\n",
      " [0.3711148 ]\n",
      " [0.42589307]\n",
      " [0.38915366]\n",
      " [0.42824107]\n",
      " [0.38764006]\n",
      " [0.4838857 ]\n",
      " [0.4893371 ]\n",
      " [0.4734158 ]\n",
      " [0.4443286 ]\n",
      " [0.37540495]\n",
      " [0.39036924]\n",
      " [0.44267237]\n",
      " [0.46056813]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['score']=pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>[point, today, someone, says, something, remot...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.451130</td>\n",
       "      <td>[[0.27355012, 0.030854275, 0.0725501, 0.058589...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>[game, day, minus, #relentless]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.378544</td>\n",
       "      <td>[[-0.062490027, -0.046009917, 0.018530663, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>[game, pissed, off, than, game, year, blood, b...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.510505</td>\n",
       "      <td>[[-0.21455964, 0.009541917, 0.15138617, -0.157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>[ive, found, candice, candace, she, pout, she,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.373545</td>\n",
       "      <td>[[-0.18939371, 0.05794645, -0.04610769, 0.0864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>[cant, come, muma, th, after, tweets, then, #s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.474511</td>\n",
       "      <td>[[0.055749744, 0.199722, 0.5565932, -0.1949415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>[what, supposed, animosity, bullshit, con, ira...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.444329</td>\n",
       "      <td>[[-0.073396154, 0.24903403, -0.1305108, 0.0700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>[byus, offense, score, vs, wvu]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375405</td>\n",
       "      <td>[[-0.72507215, -0.6317022, -0.17955363, 0.0976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>[id, love, gyimah, action, his, coach, holding...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.390369</td>\n",
       "      <td>[[-0.917267, 0.029235095, -0.12552397, -0.4948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>[forgiving, means, operating, gods, spirit, am...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.442672</td>\n",
       "      <td>[[0.026432868, 0.3324353, -0.22418864, -0.1191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>[ive, got, lot, tokens, saved, wanna, spam, ev...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.460568</td>\n",
       "      <td>[[-0.0750121, 0.17871594, -0.030560482, -0.190...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  \\\n",
       "0    10941  [point, today, someone, says, something, remot...   anger   \n",
       "1    10942                    [game, day, minus, #relentless]   anger   \n",
       "2    10943  [game, pissed, off, than, game, year, blood, b...   anger   \n",
       "3    10944  [ive, found, candice, candace, she, pout, she,...   anger   \n",
       "4    10945  [cant, come, muma, th, after, tweets, then, #s...   anger   \n",
       "..     ...                                                ...     ...   \n",
       "755  11696  [what, supposed, animosity, bullshit, con, ira...   anger   \n",
       "756  11697                    [byus, offense, score, vs, wvu]   anger   \n",
       "757  11698  [id, love, gyimah, action, his, coach, holding...   anger   \n",
       "758  11699  [forgiving, means, operating, gods, spirit, am...   anger   \n",
       "759  11700  [ive, got, lot, tokens, saved, wanna, spam, ev...   anger   \n",
       "\n",
       "        score                                           features  \n",
       "0    0.451130  [[0.27355012, 0.030854275, 0.0725501, 0.058589...  \n",
       "1    0.378544  [[-0.062490027, -0.046009917, 0.018530663, 0.1...  \n",
       "2    0.510505  [[-0.21455964, 0.009541917, 0.15138617, -0.157...  \n",
       "3    0.373545  [[-0.18939371, 0.05794645, -0.04610769, 0.0864...  \n",
       "4    0.474511  [[0.055749744, 0.199722, 0.5565932, -0.1949415...  \n",
       "..        ...                                                ...  \n",
       "755  0.444329  [[-0.073396154, 0.24903403, -0.1305108, 0.0700...  \n",
       "756  0.375405  [[-0.72507215, -0.6317022, -0.17955363, 0.0976...  \n",
       "757  0.390369  [[-0.917267, 0.029235095, -0.12552397, -0.4948...  \n",
       "758  0.442672  [[0.026432868, 0.3324353, -0.22418864, -0.1191...  \n",
       "759  0.460568  [[-0.0750121, 0.17871594, -0.030560482, -0.190...  \n",
       "\n",
       "[760 rows x 5 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop('features',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>[point, today, someone, says, something, remot...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.451130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>[game, day, minus, #relentless]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.378544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>[game, pissed, off, than, game, year, blood, b...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.510505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>[ive, found, candice, candace, she, pout, she,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.373545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>[cant, come, muma, th, after, tweets, then, #s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.474511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>[what, supposed, animosity, bullshit, con, ira...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.444329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>[byus, offense, score, vs, wvu]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>[id, love, gyimah, action, his, coach, holding...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.390369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>[forgiving, means, operating, gods, spirit, am...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.442672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>[ive, got, lot, tokens, saved, wanna, spam, ev...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.460568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  \\\n",
       "0    10941  [point, today, someone, says, something, remot...   anger   \n",
       "1    10942                    [game, day, minus, #relentless]   anger   \n",
       "2    10943  [game, pissed, off, than, game, year, blood, b...   anger   \n",
       "3    10944  [ive, found, candice, candace, she, pout, she,...   anger   \n",
       "4    10945  [cant, come, muma, th, after, tweets, then, #s...   anger   \n",
       "..     ...                                                ...     ...   \n",
       "755  11696  [what, supposed, animosity, bullshit, con, ira...   anger   \n",
       "756  11697                    [byus, offense, score, vs, wvu]   anger   \n",
       "757  11698  [id, love, gyimah, action, his, coach, holding...   anger   \n",
       "758  11699  [forgiving, means, operating, gods, spirit, am...   anger   \n",
       "759  11700  [ive, got, lot, tokens, saved, wanna, spam, ev...   anger   \n",
       "\n",
       "        score  \n",
       "0    0.451130  \n",
       "1    0.378544  \n",
       "2    0.510505  \n",
       "3    0.373545  \n",
       "4    0.474511  \n",
       "..        ...  \n",
       "755  0.444329  \n",
       "756  0.375405  \n",
       "757  0.390369  \n",
       "758  0.442672  \n",
       "759  0.460568  \n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
